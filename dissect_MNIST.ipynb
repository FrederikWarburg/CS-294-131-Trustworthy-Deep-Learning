{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FrederikWarburg/CS-294-131-Trustworthy-Deep-Learning/blob/master/dissect_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "i_sBdOspr-zL",
    "outputId": "f1e4681e-8a87-4db7-a15a-3d191636249e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting netdissect from git+git://github.com/davidbau/quick-netdissect.git#egg=netdissect\n",
      "  Cloning git://github.com/davidbau/quick-netdissect.git to /tmp/pip-install-fq4hn8gl/netdissect\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from netdissect) (1.14.6)\n",
      "Requirement already satisfied: Pillow>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from netdissect) (4.1.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from netdissect) (1.1.0)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from netdissect) (1.0.1.post2)\n",
      "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from netdissect) (0.2.2.post3)\n",
      "Requirement already satisfied: tqdm>=4.23.4 in /usr/local/lib/python3.6/dist-packages (from netdissect) (4.28.1)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow>=4.1.0->netdissect) (0.46)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->netdissect) (1.11.0)\n",
      "Building wheels for collected packages: netdissect\n",
      "  Building wheel for netdissect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-q5v5u7h6/wheels/95/03/aa/c38949a7269a6ee2f0ceb9e98b54e67fc7f9bfc5b47d1c5e4f\n",
      "Successfully built netdissect\n",
      "Installing collected packages: netdissect\n",
      "Successfully installed netdissect-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install git+git://github.com/davidbau/quick-netdissect.git#egg=netdissect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1.post2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qdRVoamxCyUF",
    "outputId": "6eafacf9-4ed4-467a-da16-a6c1173b9a96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/frederikwarburg/anaconda3/lib/python3.6/site-packages (1.0.1.post2)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python35.zip',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/plat-darwin',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/lib-dynload',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/torchvision-0.2.1-py3.5.egg',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/IPython/extensions',\n",
       " '/Users/frederikwarburg/.ipython',\n",
       " '/Users/frederikwarburg/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/wgan-gp/',\n",
       " '/Users/frederikwarburg/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/quick-netdissect/']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/wgan-gp/\")\n",
    "sys.path.append(os.getcwd() + \"/quick-netdissect/\")\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "AyDPTFay_xOO",
    "outputId": "76ced54a-5a14-490e-a2d8-9ec64afd130e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (latent_to_features): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (features_to_image): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ConvTranspose2d(16, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generator = torch.load(\"wgan-gp/mnist_models/gen_mnist_model_epoch_200.pt\", map_location='cpu')\n",
    "print(generator)\n",
    "# generater.load_state_dict(torch.load(\".sample_data/gen_mnist_model_epoch_200.pt\", map_location='cpu'))\n",
    "# generater.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PTWwHQA2tnxM"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "\n",
    "from torchvision.datasets.folder import default_loader\n",
    "\n",
    "def get_multi_mnist_dataloaders(batch_size=128):\n",
    "    # Resize images so they are a power of 2\n",
    "    all_transforms = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "#         transforms.Resize(32),\n",
    "        transforms.Resize(100),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_data = MultiMNIST('data/multi_mnist/MNIST_synthetic_31_3.h5',  train = True, transform = all_transforms)\n",
    "    test_data = MultiMNIST('data/multi_mnist/MNIST_synthetic_31_3.h5', train = False, transform = all_transforms)\n",
    "\n",
    "    # Create dataloaders\n",
    "#     train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "#     test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "#     return train_loader, test_loader\n",
    "    return train_data, test_data\n",
    "\n",
    "class MultiMNIST(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, path = 'data/multi_mnist/MNIST_synthetic_31_3.h5', train = True, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        super(MultiMNIST, self).__init__()\n",
    "        \n",
    "        #['color', 'object', 'part', 'material', 'scene', 'texture']\n",
    "        self.categories = ['digit']\n",
    "        \n",
    "        \"\"\"\n",
    "        self.category_info = OrderedDict([('digit',\n",
    "              {'count': '10',\n",
    "               'first': '1',\n",
    "               'frequency': '50000',\n",
    "               'last': '10',\n",
    "               'name': 'digit'})])\n",
    "        self.category_label = {'digit': [{'code': 0,\n",
    "                                           'coverage': 0.0,\n",
    "                                           'frequency': 0,\n",
    "                                           'name': '',\n",
    "                                           'number': 0},\n",
    "                                          {'code': 1,\n",
    "                                           'coverage': 11135.3204744,\n",
    "                                           'frequency': 62358,\n",
    "                                           'name': 'one',\n",
    "                                           'number': 1},\n",
    "                                          {'code': 2,\n",
    "                                           'coverage': 12712.8431287,\n",
    "                                           'frequency': 62310,\n",
    "                                           'name': 'two',\n",
    "                                           'number': 2},\n",
    "                                          {'code': 3,\n",
    "                                           'coverage': 5778.03820407,\n",
    "                                           'frequency': 62054,\n",
    "                                           'name': 'three',\n",
    "                                           'number': 3},\n",
    "                                          {'code': 4,\n",
    "                                           'coverage': 14549.6524542,\n",
    "                                           'frequency': 61583,\n",
    "                                           'name': 'four',\n",
    "                                           'number': 4},\n",
    "                                          {'code': 5,\n",
    "                                           'coverage': 5049.98973538,\n",
    "                                           'frequency': 61508,\n",
    "                                           'name': 'five',\n",
    "                                           'number': 5},\n",
    "                                          {'code': 6,\n",
    "                                           'coverage': 1478.51858238,\n",
    "                                           'frequency': 60755,\n",
    "                                           'name': 'six',\n",
    "                                           'number': 6},\n",
    "                                          {'code': 7,\n",
    "                                           'coverage': 865.041518839,\n",
    "                                           'frequency': 59516,\n",
    "                                           'name': 'seven',\n",
    "                                           'number': 7},\n",
    "                                          {'code': 8,\n",
    "                                           'coverage': 4899.17412108,\n",
    "                                           'frequency': 57825,\n",
    "                                           'name': 'eight',\n",
    "                                           'number': 8},\n",
    "                                          {'code': 9,\n",
    "                                           'coverage': 2730.58728273,\n",
    "                                           'frequency': 57560,\n",
    "                                           'name': 'nine',\n",
    "                                           'number': 9},\n",
    "                                          {'code': 10,\n",
    "                                           'coverage': 1678.05972937,\n",
    "                                           'frequency': 55938,\n",
    "                                           'name': 'zero',\n",
    "                                           'number': 10}]}\n",
    "        \"\"\"\n",
    "        #self.category_map = {'color': np.array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int16)}\n",
    "        self.directory = 'data/multiMnist/'\n",
    "        self.image = self.images()\n",
    "        self.include_bincount = True\n",
    "        self.label_category = np.zeros(50000,dtype=int)\n",
    "        self.label_info = None\n",
    "        self.labels = self.labels()\n",
    "        self.loader = default_loader\n",
    "        self.max_segment_depth = 1\n",
    "        self.num_labels = 10*10*10\n",
    "        self.resdir = 'data/multiMnist/'\n",
    "        self.resolution = 64\n",
    "        self.transform_image = transform\n",
    "        self.transform_segment = transform\n",
    "        \n",
    "    def labels(self):\n",
    "        labels = []\n",
    "        for i in range(10):\n",
    "            for j in range(10):\n",
    "                for k in range(10):\n",
    "                    label = np.array([i,j,k])\n",
    "                    labels.append(label)\n",
    "                    \n",
    "        return labels\n",
    "    \n",
    "    def images(self):\n",
    "        images = []\n",
    "        for i in range(50000):\n",
    "            n = str(i)\n",
    "            filename = n.zfill(6) +'.png'\n",
    "            \n",
    "            dict_ = {}\n",
    "            dict_['digit'] = [filename]\n",
    "            dict_['ih'] = 64\n",
    "            dict_['image'] = filename\n",
    "            dict_['iw'] = 64\n",
    "            dict_['sh'] = 32\n",
    "            dict_['sw'] = 32\n",
    "            \n",
    "            images.append(dict_)\n",
    "            \n",
    "        return images\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):#, seg=False):\n",
    "        \n",
    "        n = str(index)\n",
    "        filename = n.zfill(6) +'.png'\n",
    "                        \n",
    "        img = Image.open('data/multiMnist/images/'+filename)\n",
    "        file = open('data/multiMnist/label/' + filename.replace('png','txt'), 'r')\n",
    "        target = file.read() \n",
    "        file.close()\n",
    "        target = torch.as_tensor(np.array(target), dtype=torch.int32)\n",
    "        seg = Image.open('data/multiMnist/seg/'+filename)\n",
    "        \n",
    "        if self.transform_image:\n",
    "            print(np.shape(img),np.min(img),np.max(img),type(img))\n",
    "            print(np.shape(seg), np.min(seg),np.max(seg), type(seg))\n",
    "            img = self.transform_image(img)\n",
    "            seg = self.transform_image(seg)\n",
    "\n",
    "        seg = torch.as_tensor(seg,dtype=torch.int64)    \n",
    "            \n",
    "        return (img, seg, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/wgan-gp/\")\n",
    "sys.path.append(os.getcwd() + \"/quick-netdissect/\")\n",
    "sys.path\n",
    "\n",
    "import torch\n",
    "\n",
    "from netdissect import retain_layers, dissect\n",
    "from netdissect import ReverseNormalize\n",
    "import torchvision.models as models\n",
    "from netdissect import BrodenDataset\n",
    "from netdissect.progress import verbose_progress\n",
    "verbose_progress(True)\n",
    "from torchvision.models import alexnet\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3rpC_C88qsv7"
   },
   "outputs": [],
   "source": [
    "def eval_constructor(term, construct_types=True):\n",
    "    '''\n",
    "    Used to evaluate an arbitrary command-line constructor specifying\n",
    "    a class, with automatic import of global module names.\n",
    "    '''\n",
    "    from collections import defaultdict\n",
    "    from importlib import import_module\n",
    "\n",
    "    class DictNamespace(object):\n",
    "        def __init__(self, d):\n",
    "            self.__d__ = d\n",
    "        def __getattr__(self, key):\n",
    "            return self.__d__[key]\n",
    "\n",
    "    class AutoImportDict(defaultdict):\n",
    "        def __init__(self, parent=None):\n",
    "            super().__init__()\n",
    "            self.parent = parent\n",
    "        def __missing__(self, key):\n",
    "            if self.parent is not None:\n",
    "                key = self.parent + '.' + key\n",
    "            if hasattr(__builtins__, key):\n",
    "                return getattr(__builtins__, key)\n",
    "            mdl = import_module(key)\n",
    "            # Return an AutoImportDict for any namespace packages\n",
    "            if hasattr(mdl, '__path__') and not hasattr(mdl, '__file__'):\n",
    "                return DictNamespace(AutoImportDict(key))\n",
    "            return mdl\n",
    "\n",
    "    obj = eval(term, {}, AutoImportDict())\n",
    "    if isinstance(obj, type):\n",
    "        obj = obj()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WVqROMVQqiHc"
   },
   "outputs": [],
   "source": [
    "model = eval_constructor('torchvision.models.alexnet(pretrained=True)')\n",
    "model.eval()\n",
    "\n",
    "retain_layers(model, [\n",
    "        ('features.0', 'conv1'),\n",
    "        ('features.3', 'conv2'),\n",
    "        ('features.6', 'conv3'),\n",
    "        ('features.8', 'conv4'),\n",
    "        ('features.10', 'conv5') ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGE_STDEV = [0.229, 0.224, 0.225]\n",
    "\n",
    "\"\"\"\n",
    "bds = BrodenDataset(directory='quick-netdissect/dataset/broden',broden_version=1,download=False,resolution=227,\n",
    "                   transform_image=transforms.Compose([\n",
    "                        transforms.Resize(224),\n",
    "                        transforms.ToTensor()]))\n",
    "\n",
    "\"\"\"\n",
    "bds = MultiMNIST(path = 'data/multi_mnist/MNIST_synthetic_31_3.h5',train = True, \n",
    "                 transform= transforms.Compose([\n",
    "                        transforms.Resize(224),\n",
    "                        transforms.ToTensor()]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab295a6f6fc44c89dbe84f5f3136cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Quantiles', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3) 0 255 <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "(64, 64, 3) 0 255 <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "(64, 64, 3) 0 254 <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "(64, 64, 3) 0 255 <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "(64, 64, 3) 0 255 <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "(64, 64, 3) 0 255 <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "(64, 64, 3) 0 255 <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "(64, 64, 3) 0 255 <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "(64, 64, 3) 0 255 <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "(64, 64, 3) 0 255 <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "(64, 64, 3) 0 255 <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "(64, 64, 3) 0 255 <class 'PIL.PngImagePlugin.PngImageFile'>\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from netdissect.sampler import FixedSubsetSampler\n",
    "from netdissect.progress import verbose_progress, default_progress, print_progress\n",
    "\n",
    "segloader = torch.utils.data.DataLoader(bds,\n",
    "        batch_size=2, num_workers=1, sampler=  FixedSubsetSampler([0,1,2,3,4,5]))\n",
    "\n",
    "progress = default_progress(verbose=True)\n",
    "for i, batch in enumerate(progress(segloader, desc='Quantiles')):\n",
    "    print(i)\n",
    "    #model(batch[0].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bds.categories\n",
    "#bds.category_info\n",
    "#bds.category_label\n",
    "#bds.category_map\n",
    "#bds.directory\n",
    "#bds.image\n",
    "#bds.include_bincount\n",
    "#bds.label_category\n",
    "#bds.label_info\n",
    "#bds.labels\n",
    "#bds.loader\n",
    "#bds.max_segment_depth\n",
    "#bds.num_labels\n",
    "#bds.resdir\n",
    "#bds.resolution\n",
    "#bds.transform_image\n",
    "#bds.transform_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'digit': ['001000.png'], 'iw': 64, 'image': '001000.png', 'ih': 64, 'sw': 32, 'sh': 32}\n",
      "data/multiMnist/images/001000.png data/multiMnist/images/001000.png\n",
      "255\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 1000\n",
    "print(bds.image[i])\n",
    "im_name = bds.resdir + 'images/'+ bds.image[i]['image']\n",
    "color_name = bds.resdir + 'images/' + bds.image[i]['digit'][0]\n",
    "print(im_name, color_name)\n",
    "#print(os.path.exists('quick-netdissect/dataset/broden/broden1_227/images/'))\n",
    "im = cv2.imread(im_name)\n",
    "\n",
    "print(np.max(im))\n",
    "#print(im)\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "color_im = cv2.imread(color_name)\n",
    "print(np.min(color_im),np.max(color_im))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are startingg!\n",
      "PROGRESS: method dissect, after loading device\n",
      "PROGRESS: method dissect, after loading segloader\n",
      "VERBOSE: segloader: <torch.utils.data.dataloader.DataLoader object at 0xb2dee0898>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbd2fe879b54209b2e457d5e30fd1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Quantiles', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Traceback (most recent call last):\n  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-48-eca0854d6a4c>\", line 160, in __getitem__\n    target = torch.as_tensor(np.array(target), dtype=torch.int32)\nTypeError: can't convert np.ndarray of type numpy.str_. The only supported types are: double, float, float16, int64, int32, and uint8.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-b65f18fe5a2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mrecover_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mReverseNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_MEAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_STDEV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         examples_per_unit=1)\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/quick-netdissect/netdissect/dissection.py\u001b[0m in \u001b[0;36mdissect\u001b[0;34m(outdir, model, dataset, recover_image, quantile_threshold, iou_threshold, examples_per_unit, batch_size, num_workers, make_images, make_labels, make_report, make_single_images, netname, meta, settings)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         quantiles, topk = collect_quantiles_and_topk(model, segloader,\n\u001b[0;32m---> 80\u001b[0;31m                 recover_image=recover_image, k=examples_per_unit)\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PROGRESS: method dissect, after collect_quantiles_and_topk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/quick-netdissect/netdissect/dissection.py\u001b[0m in \u001b[0;36mcollect_quantiles_and_topk\u001b[0;34m(model, segloader, recover_image, k, resolution)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0mprogress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Quantiles'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;31m# We don't actually care about the model output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.5/site-packages/tqdm/_tqdm_notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.5/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Traceback (most recent call last):\n  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-48-eca0854d6a4c>\", line 160, in __getitem__\n    target = torch.as_tensor(np.array(target), dtype=torch.int32)\nTypeError: can't convert np.ndarray of type numpy.str_. The only supported types are: double, float, float16, int64, int32, and uint8.\n"
     ]
    }
   ],
   "source": [
    "dissect('result/dissect', model, bds,\n",
    "        recover_image=ReverseNormalize(IMAGE_MEAN, IMAGE_STDEV),\n",
    "        batch_size=1,\n",
    "        examples_per_unit=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.as_tensor('[a,b,c]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1, 1, 1]'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "readable_replacements = [(re.compile(r[0]), r[1]) for r in [\n",
    "    (r'-[sc]$', ''),\n",
    "    (r'_', ' '),\n",
    "    ]]\n",
    "\n",
    "def readable(label):\n",
    "    for pattern, subst in readable_replacements:\n",
    "        label= re.sub(pattern, subst, label)\n",
    "    return label\n",
    "\n",
    "readable(str([1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot use a string pattern on a bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-aefcd95efc76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m label_and_cat_names = [(readable(label),\n\u001b[1;32m      3\u001b[0m     catnames[bds.label_category[i]])\n\u001b[0;32m----> 4\u001b[0;31m         for i, label in enumerate(bds.labels)]\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-aefcd95efc76>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m label_and_cat_names = [(readable(label),\n\u001b[1;32m      3\u001b[0m     catnames[bds.label_category[i]])\n\u001b[0;32m----> 4\u001b[0;31m         for i, label in enumerate(bds.labels)]\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-f161dee92c9b>\u001b[0m in \u001b[0;36mreadable\u001b[0;34m(label)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubst\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreadable_replacements\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.5/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": [
    "catnames = bds.categories\n",
    "label_and_cat_names = [(readable(label), catnames[bds.label_category[i]]) for i, label in enumerate(bds.labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(bds.labels):\n",
    "    #label = readable(str(label))\n",
    "    cat_names = catnames[int(bds.label_category[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bds.label_category[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "dissect_MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python (pyspark)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
