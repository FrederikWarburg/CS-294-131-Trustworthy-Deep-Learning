{
 "cells": [
  {
<<<<<<< HEAD
=======
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FrederikWarburg/CS-294-131-Trustworthy-Deep-Learning/blob/master/dissect_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
<<<<<<< HEAD
     "height": 301.0
    },
    "colab_type": "code",
    "id": "i_sBdOspr-zL",
    "outputId": "f1e4681e-8a87-4db7-a15a-3d191636249e"
=======
     "height": 301
    },
    "colab_type": "code",
    "id": "i_sBdOspr-zL",
    "outputId": "f1e4681e-8a87-4db7-a15a-3d191636249e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting netdissect from git+git://github.com/davidbau/quick-netdissect.git#egg=netdissect\n",
      "  Cloning git://github.com/davidbau/quick-netdissect.git to /tmp/pip-install-fq4hn8gl/netdissect\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from netdissect) (1.14.6)\n",
      "Requirement already satisfied: Pillow>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from netdissect) (4.1.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from netdissect) (1.1.0)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from netdissect) (1.0.1.post2)\n",
      "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from netdissect) (0.2.2.post3)\n",
      "Requirement already satisfied: tqdm>=4.23.4 in /usr/local/lib/python3.6/dist-packages (from netdissect) (4.28.1)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow>=4.1.0->netdissect) (0.46)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->netdissect) (1.11.0)\n",
      "Building wheels for collected packages: netdissect\n",
      "  Building wheel for netdissect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-q5v5u7h6/wheels/95/03/aa/c38949a7269a6ee2f0ceb9e98b54e67fc7f9bfc5b47d1c5e4f\n",
      "Successfully built netdissect\n",
      "Installing collected packages: netdissect\n",
      "Successfully installed netdissect-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install git+git://github.com/davidbau/quick-netdissect.git#egg=netdissect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1.post2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qdRVoamxCyUF",
    "outputId": "6eafacf9-4ed4-467a-da16-a6c1173b9a96"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Collecting netdissect from git+git://github.com/davidbau/quick-netdissect.git#egg=netdissect\n",
      "  Cloning git://github.com/davidbau/quick-netdissect.git to c:\\users\\lucy\\appdata\\local\\temp\\pip-build-mv64krpi\\netdissect\n",
      "fatal: unable to connect to github.com:\n",
      "github.com[0: 192.30.255.112]: errno=Invalid argument\n",
      "github.com[1: 192.30.255.113]: errno=Invalid argument\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command \"git clone -q git://github.com/davidbau/quick-netdissect.git C:\\Users\\Lucy\\AppData\\Local\\Temp\\pip-build-mv64krpi\\netdissect\" failed with error code 128 in None\n",
      "You are using pip version 9.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+git://github.com/davidbau/quick-netdissect.git#egg=netdissect"
=======
      "Requirement already satisfied: torch in /Users/frederikwarburg/anaconda3/lib/python3.6/site-packages (1.0.1.post2)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python35.zip',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/plat-darwin',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/lib-dynload',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/torchvision-0.2.1-py3.5.egg',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/IPython/extensions',\n",
       " '/Users/frederikwarburg/.ipython',\n",
       " '/Users/frederikwarburg/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/wgan-gp/',\n",
       " '/Users/frederikwarburg/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/quick-netdissect/']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/wgan-gp/\")\n",
    "sys.path.append(os.getcwd() + \"/quick-netdissect/\")\n",
    "sys.path"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "colab_type": "code",
    "id": "qdRVoamxCyUF",
    "outputId": "6eafacf9-4ed4-467a-da16-a6c1173b9a96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\lucy\\anaconda3\\lib\\site-packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
=======
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "AyDPTFay_xOO",
    "outputId": "76ced54a-5a14-490e-a2d8-9ec64afd130e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (latent_to_features): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (features_to_image): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ConvTranspose2d(16, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generator = torch.load(\"wgan-gp/mnist_models/gen_mnist_model_epoch_200.pt\", map_location='cpu')\n",
    "print(generator)\n",
    "# generater.load_state_dict(torch.load(\".sample_data/gen_mnist_model_epoch_200.pt\", map_location='cpu'))\n",
    "# generater.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PTWwHQA2tnxM"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "\n",
    "from torchvision.datasets.folder import default_loader\n",
    "\n",
    "def get_multi_mnist_dataloaders(batch_size=128):\n",
    "    # Resize images so they are a power of 2\n",
    "    all_transforms = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "#         transforms.Resize(32),\n",
    "        transforms.Resize(100),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_data = MultiMNIST('data/multi_mnist/MNIST_synthetic_31_3.h5',  train = True, transform = all_transforms)\n",
    "    test_data = MultiMNIST('data/multi_mnist/MNIST_synthetic_31_3.h5', train = False, transform = all_transforms)\n",
    "\n",
    "    # Create dataloaders\n",
    "#     train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "#     test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "#     return train_loader, test_loader\n",
    "    return train_data, test_data\n",
    "\n",
    "class MultiMNIST(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, path = 'data/multi_mnist/MNIST_synthetic_31_3.h5', train = True, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        super(MultiMNIST, self).__init__()\n",
    "        self.path = path\n",
    "        \n",
    "        f = h5py.File(self.path, 'r')\n",
    "\n",
    "        \n",
    "        self.X = list(f['train_dataset'])\n",
    "        self.y = list(f['train_labels'])\n",
    "        self.seg = list(f['train_segmentations'])\n",
    "\n",
    "        #['color', 'object', 'part', 'material', 'scene', 'texture']\n",
    "        self.categories = ['digit']\n",
    "        \n",
    "        \"\"\"\n",
    "        self.category_info = OrderedDict([('digit',\n",
    "              {'count': '10',\n",
    "               'first': '1',\n",
    "               'frequency': '50000',\n",
    "               'last': '10',\n",
    "               'name': 'digit'})])\n",
    "        self.category_label = {'digit': [{'code': 0,\n",
    "                                           'coverage': 0.0,\n",
    "                                           'frequency': 0,\n",
    "                                           'name': '',\n",
    "                                           'number': 0},\n",
    "                                          {'code': 1,\n",
    "                                           'coverage': 11135.3204744,\n",
    "                                           'frequency': 62358,\n",
    "                                           'name': 'one',\n",
    "                                           'number': 1},\n",
    "                                          {'code': 2,\n",
    "                                           'coverage': 12712.8431287,\n",
    "                                           'frequency': 62310,\n",
    "                                           'name': 'two',\n",
    "                                           'number': 2},\n",
    "                                          {'code': 3,\n",
    "                                           'coverage': 5778.03820407,\n",
    "                                           'frequency': 62054,\n",
    "                                           'name': 'three',\n",
    "                                           'number': 3},\n",
    "                                          {'code': 4,\n",
    "                                           'coverage': 14549.6524542,\n",
    "                                           'frequency': 61583,\n",
    "                                           'name': 'four',\n",
    "                                           'number': 4},\n",
    "                                          {'code': 5,\n",
    "                                           'coverage': 5049.98973538,\n",
    "                                           'frequency': 61508,\n",
    "                                           'name': 'five',\n",
    "                                           'number': 5},\n",
    "                                          {'code': 6,\n",
    "                                           'coverage': 1478.51858238,\n",
    "                                           'frequency': 60755,\n",
    "                                           'name': 'six',\n",
    "                                           'number': 6},\n",
    "                                          {'code': 7,\n",
    "                                           'coverage': 865.041518839,\n",
    "                                           'frequency': 59516,\n",
    "                                           'name': 'seven',\n",
    "                                           'number': 7},\n",
    "                                          {'code': 8,\n",
    "                                           'coverage': 4899.17412108,\n",
    "                                           'frequency': 57825,\n",
    "                                           'name': 'eight',\n",
    "                                           'number': 8},\n",
    "                                          {'code': 9,\n",
    "                                           'coverage': 2730.58728273,\n",
    "                                           'frequency': 57560,\n",
    "                                           'name': 'nine',\n",
    "                                           'number': 9},\n",
    "                                          {'code': 10,\n",
    "                                           'coverage': 1678.05972937,\n",
    "                                           'frequency': 55938,\n",
    "                                           'name': 'zero',\n",
    "                                           'number': 10}]}\n",
    "        \"\"\"\n",
    "        #self.category_map = {'color': np.array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int16)}\n",
    "        self.directory = 'data/multiMnist/'\n",
    "        self.image = self.images()\n",
    "        self.include_bincount = True\n",
    "        self.label_category = np.zeros(50000)\n",
    "        self.label_info = None\n",
    "        self.labels = self.labels()\n",
    "        self.loader = default_loader\n",
    "        self.max_segment_depth = 1\n",
    "        self.num_labels = 10*10*10\n",
    "        self.resdir = 'data/multiMnist/'\n",
    "        self.resolution = 64\n",
    "        self.transform_image = transform\n",
    "        self.transform_segment = transform\n",
    "        \n",
    "    def labels(self):\n",
    "        labels = []\n",
    "        for i in range(10):\n",
    "            for j in range(10):\n",
    "                for k in range(10):\n",
    "                    label = str([i,j,k])\n",
    "                    labels.append(label)\n",
    "                    \n",
    "        return labels\n",
    "    \n",
    "    def images(self):\n",
    "        images = []\n",
    "        for i in range(50000):\n",
    "            n = str(i)\n",
    "            filename = n.zfill(6) +'.png'\n",
    "            \n",
    "            dict_ = {}\n",
    "            dict_['digit'] = [filename]\n",
    "            dict_['ih'] = 64\n",
    "            dict_['image'] = filename\n",
    "            dict_['iw'] = 64\n",
    "            dict_['sh'] = 32\n",
    "            dict_['sw'] = 32\n",
    "            \n",
    "            images.append(dict_)\n",
    "            \n",
    "        return images\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):#, seg=False):\n",
    "\n",
    "        img = self.X[index]\n",
    "        target = self.y[index]\n",
    "        seg = self.seg[index]\n",
    "\n",
    "        if self.transform_image:\n",
    "            img = self.transform_image(img)\n",
    "            seg = self.transform_image(seg)\n",
    "\n",
    "        return img, target, seg"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 57,
=======
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sxcFUhfCg3pG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-74de346835c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mrecover_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mReverseNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         examples_per_unit=10)\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/quick-netdissect/netdissect/dissection.py\u001b[0m in \u001b[0;36mdissect\u001b[0;34m(outdir, model, dataset, recover_image, quantile_threshold, iou_threshold, examples_per_unit, batch_size, num_workers, make_images, make_labels, make_report, make_single_images, netname, meta, settings)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 pin_memory=(device.type == 'cuda'))\n\u001b[1;32m     71\u001b[0m         quantiles, topk = collect_quantiles_and_topk(model, segloader,\n\u001b[0;32m---> 72\u001b[0;31m                 recover_image=recover_image, k=examples_per_unit)\n\u001b[0m\u001b[1;32m     73\u001b[0m         levels = {k: qc.quantiles([1.0 - quantile_threshold])[:,0]\n\u001b[1;32m     74\u001b[0m                 for k, qc in quantiles.items()}\n",
      "\u001b[0;32m~/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/quick-netdissect/netdissect/dissection.py\u001b[0m in \u001b[0;36mcollect_quantiles_and_topk\u001b[0;34m(model, segloader, recover_image, k, resolution)\u001b[0m\n\u001b[1;32m    393\u001b[0m                         \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                         ).contiguous().view(-1, value.shape[1])\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mquantiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mtopks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mquantiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/quick-netdissect/netdissect/runningstats.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, incoming)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# Convert to a flat torch array.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_every\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincoming\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# If we are sampling, then subsample a large chunk at a time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/quick-netdissect/netdissect/runningstats.py\u001b[0m in \u001b[0;36m_add_every\u001b[0;34m(self, incoming)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mavailable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mavailable\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m                     \u001b[0;31m# If we shifted by subsampling, then subsample.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mincoming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mincoming\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/quick-netdissect/netdissect/runningstats.py\u001b[0m in \u001b[0;36m_shift\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirstfree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_extremes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "!pip install torch"
=======
    "from netdissect import retain_layers, dissect\n",
    "from netdissect import ReverseNormalize\n",
    "i\n",
    "\n",
    "generator.eval()\n",
    "#generator.cuda()\n",
    "  \n",
    "#   for name, layer in generator.named_modules():\n",
    "#     print(name)\n",
    "#============ result: \n",
    "# latent_to_features\n",
    "# latent_to_features.0\n",
    "# latent_to_features.1\n",
    "# features_to_image\n",
    "# features_to_image.0\n",
    "# features_to_image.1\n",
    "# features_to_image.2\n",
    "# features_to_image.3\n",
    "# features_to_image.4\n",
    "# features_to_image.5\n",
    "# features_to_image.6\n",
    "# features_to_image.7\n",
    "# features_to_image.8\n",
    "# features_to_image.9\n",
    "# features_to_image.10\n",
    "\n",
    "retain_layers(generator, ['features_to_image.0',\n",
    "                          'features_to_image.1', \n",
    "                          'features_to_image.2', \n",
    "                          'features_to_image.3', \n",
    "                          'features_to_image.4',\n",
    "                          'features_to_image.5',\n",
    "                          'features_to_image.6',\n",
    "                          'features_to_image.7',\n",
    "                          'features_to_image.8',\n",
    "                          'features_to_image.9',\n",
    "                          'features_to_image.10'])\n",
    "bds, _ = get_multi_mnist_dataloaders()\n",
    "\n",
    "dissect('sample_data/', generator, bds,\n",
    "        recover_image=ReverseNormalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        batch_size=100,\n",
    "        examples_per_unit=10)\n"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "outputs": [],
   "source": [
    "<a href=\"https://colab.research.google.com/github/FrederikWarburg/CS-294-131-Trustworthy-Deep-Learning/blob/master/dissect_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
=======
   "execution_count": 1,
>>>>>>> 48b6c627ed647b6b208018ad087189a95b7f8627
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/wgan-gp/\")\n",
    "sys.path.append(os.getcwd() + \"/quick-netdissect/\")\n",
    "sys.path\n",
    "\n",
    "import torch\n",
    "\n",
    "from netdissect import retain_layers, dissect\n",
    "from netdissect import ReverseNormalize\n",
    "import torchvision.models as models\n",
    "from netdissect import BrodenDataset\n",
    "from netdissect.progress import verbose_progress\n",
    "verbose_progress(True)\n",
    "from torchvision.models import alexnet\n",
<<<<<<< HEAD
    "from torchvision import transforms\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
=======
    "from torchvision import transforms"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
>>>>>>> 48b6c627ed647b6b208018ad087189a95b7f8627
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qmLgm0-vs6sk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, img_size, latent_dim, dim):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_size = img_size\n",
    "        self.feature_sizes = int(self.img_size[0] / 16), int(self.img_size[1] / 16)\n",
    "\n",
    "        self.latent_to_features = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 8 * dim * self.feature_sizes[0] * self.feature_sizes[1]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.features_to_image = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8 * dim, 4 * dim, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(4 * dim),\n",
    "            nn.ConvTranspose2d(4 * dim, 2 * dim, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(2 * dim),\n",
    "            nn.ConvTranspose2d(2 * dim, dim, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(dim),\n",
    "            nn.ConvTranspose2d(dim, self.img_size[2], 4, 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # Map latent into appropriate size for transposed convolutions\n",
    "        x = self.latent_to_features(input_data)\n",
    "        # Reshape\n",
    "        x = x.view(-1, 8 * self.dim, self.feature_sizes[0], self.feature_sizes[1])\n",
    "        # Return generated image\n",
    "        return self.features_to_image(x)\n",
    "\n",
    "    def sample_latent(self, num_samples):\n",
    "        return torch.randn((num_samples, self.latent_dim))"
=======
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3rpC_C88qsv7"
   },
   "outputs": [],
   "source": [
    "def eval_constructor(term, construct_types=True):\n",
    "    '''\n",
    "    Used to evaluate an arbitrary command-line constructor specifying\n",
    "    a class, with automatic import of global module names.\n",
    "    '''\n",
    "    from collections import defaultdict\n",
    "    from importlib import import_module\n",
    "\n",
    "    class DictNamespace(object):\n",
    "        def __init__(self, d):\n",
    "            self.__d__ = d\n",
    "        def __getattr__(self, key):\n",
    "            return self.__d__[key]\n",
    "\n",
    "    class AutoImportDict(defaultdict):\n",
    "        def __init__(self, parent=None):\n",
    "            super().__init__()\n",
    "            self.parent = parent\n",
    "        def __missing__(self, key):\n",
    "            if self.parent is not None:\n",
    "                key = self.parent + '.' + key\n",
    "            if hasattr(__builtins__, key):\n",
    "                return getattr(__builtins__, key)\n",
    "            mdl = import_module(key)\n",
    "            # Return an AutoImportDict for any namespace packages\n",
    "            if hasattr(mdl, '__path__') and not hasattr(mdl, '__file__'):\n",
    "                return DictNamespace(AutoImportDict(key))\n",
    "            return mdl\n",
    "\n",
    "    obj = eval(term, {}, AutoImportDict())\n",
    "    if isinstance(obj, type):\n",
    "        obj = obj()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WVqROMVQqiHc"
   },
   "outputs": [],
   "source": [
    "model = eval_constructor('torchvision.models.alexnet(pretrained=True)')\n",
    "model.eval()\n",
    "\n",
    "retain_layers(model, [\n",
    "        ('features.0', 'conv1'),\n",
    "        ('features.3', 'conv2'),\n",
    "        ('features.6', 'conv3'),\n",
    "        ('features.8', 'conv4'),\n",
<<<<<<< HEAD
    "        ('features.10', 'conv5') ])\n"
=======
    "        ('features.10', 'conv5') ])\n",
    "\n",
    "\n"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
>>>>>>> 48b6c627ed647b6b208018ad087189a95b7f8627
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.PngImagePlugin.PngImageFile"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Image.open('data/multiMnist/seg/000000.png')\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
   "execution_count": 4,
<<<<<<< HEAD
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355.0
    },
    "colab_type": "code",
    "id": "AyDPTFay_xOO",
    "outputId": "76ced54a-5a14-490e-a2d8-9ec64afd130e"
   },
=======
>>>>>>> 48b6c627ed647b6b208018ad087189a95b7f8627
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.folder import default_loader\n",
    "\n",
    "idx = 0\n",
    "record = bds.image[idx]\n",
    "image = default_loader(os.path.join(bds.resdir, 'images',\n",
    "    record['image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "for i in range(2240):\n",
    "    \n",
    "    n = str(i).zfill(6)\n",
    "    seg = cv2.imread('data/multiMnist/seg/'+n+'.png', cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.imread('data/multiMnist/img/'+n+'.png', cv2.COLOR_BGR2RGB)\n",
    "    result = Image.fromarray(img)\n",
    "    result.save('data/multiMnist/img/'+n+'.png')\n",
    "    \n",
    "    result = Image.fromarray(seg)\n",
    "    result.save('data/multiMnist/seg/'+n+'.png')"
=======
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Generator(\n",
      "  (latent_to_features): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (features_to_image): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ConvTranspose2d(16, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      ")\n"
=======
      "quick-netdissect/dataset/broden 227 False 1\n",
      "['', 'black-c', 'grey-c', 'white-c', 'brown-c', 'green-c', 'pink-c', 'purple-c', 'blue-c', 'yellow-c', 'red-c', 'orange-c', 'wall', 'sky', 'floor', 'windowpane', 'tree', 'wood', 'building', 'person', 'painted', 'head', 'leg', 'door', 'fabric', 'ceiling', 'torso', 'table', 'arm', 'eye', 'glass', 'road', 'ear', 'grass', 'metal', 'plant', 'chair', 'nose', 'car', 'neck', 'painting', 'carpet', 'hand', 'sidewalk', 'wheel', 'cabinet', 'light', 'signboard', 'mirror', 'tile', 'lamp', 'hair', 'ground', 'mouth', 'curtain', 'pole', 'mountain', 'fence', 'foot', 'street-s', 'streetlight', 'bed', 'eyebrow', 'sofa', 'handle', 'box', 'tail', 'muzzle', 'earth', 'plastic-opaque', 'bottle', 'paper', 'shelf', 'headlight', 'drawer', 'water', 'railing', 'cushion', 'book', 'flower', 'granite', 'back', 'shade', 'bedroom-s', 'ceramic', 'rock', 'seat', 'paw', 'vase', 'pot', 'flowerpot', 'sink', 'column', 'dog', 'food', 'armchair', 'faucet', 'wall socket', 'body', 'knob', 'sconce', 'pillow', 'base', 'headboard', 'stairs', 'cat', 'license plate', 'plate', 'top', 'bowl', 'screen', 'clock', 'bag', 'pillar', 'seat cushion', 'bicycle', 'stove', 'wing', 'coffee table', 'ashcan', 'roof', 'bench', 'spotlight', 'boat', 'basket', 'work surface', 'living_room-s', 'desk', 'bird', 'leather', 'bathroom-s', 'house', 'plaything', 'pane', 'kitchen-s', 'sea', 'double door', 'rim', 'television', 'taillight', 'back pillow', 'chandelier', 'balcony', 'windshield', 'switch', 'pottedplant', 'path', 'stairway', 'cup', 'van', 'cap', 'door frame', 'chest of drawers', 'truck', 'airplane', 'awning', 'traffic light', 'bannister', 'beak', 'seat base', 'poster', 'flag', 'inside arm', 'drinking glass', 'telephone', 'towel', 'frame', 'rope', 'tvmonitor', 'bush', 'bucket', 'stern', 'field', 'stool', 'tray', 'pedestal', 'fireplace', 'outside arm', 'trade name', 'oven', 'keyboard', 'footboard', 'fan', 'horse', 'motorbike', 'train', 'dining_room-s', 'plastic-clear', 'shelves', 'bathtub', 'toilet', 'refrigerator', 'saddle', 'laminate', 'apron', 'counter', 'handle bar', 'wardrobe', 'candlestick', 'computer', 'palm', 'shop window', 'brick', 'bus', 'board', 'blind', 'chimney', 'microwave', 'sand', 'track', 'fluorescent', 'step', 'sculpture', 'engine', 'countertop', 'wallpaper', 'swivel chair', 'lid', 'loudspeaker', 'side', 'skirt', 'pipe', 'chain wheel', 'skyscraper-s', 'snow', 'river', 'air conditioner', 'bumper', 'ottoman', 'jar', 'skin', 'coach', 'pack', 'highway-s', 'canopy', 'stile', 'bridge', 'blotchy', 'cardboard', 'minibike', 'figurine', 'skyscraper', 'can', 'sheep', 'concrete', 'wicker', 'mouse', 'bookcase', 'bedclothes', 'exhaust hood', 'hill', 'cow', 'napkin', 'button panel', 'doorframe', 'manhole', 'crosswalk', 'umbrella', 'case', 'autobus', 'dishwasher', 'monitor', 'container', 'shutter', 'hoof', 'front', 'water tank', 'text', 'knife', 'building_facade-s', 'crt screen', 'curb', 'magazine', 'monitoring device', 'beam', 'gate', 'dotted', 'radiator', 'platform', 'blanket', 'central reservation', 'grill', 'bulletin board', 'laptop', 'shoe', 'pool table', 'fruit', 'coffee maker', 'candle', 'backplate', 'banded', 'handbag', 'wineglass', 'mug', 'apparel', 'striped', 'land', 'pitcher', 'remote control', 'bar', 'ball', 'conference_room-s', 'hotel_room-s', 'grandstand', 'backpack', 'pane of glass', 'face', 'ladder', 'bumpy', 'hedge', 'arm panel', 'fork', 'tower', 'notebook', 'toilet tissue', 'vent', 'muntin', 'screen door', 'brush', 'heater', 'booklet', 'kitchen island', 'post', 'stretcher', 'smeared', 'knitted', 'porous', 'plane', 'fibrous', 'pitted', 'sash', 'veined', 'shower', 'mountain_snowy-s', 'perforated', 'woven', 'soap dispenser', 'meshed', 'crosshatched', 'computer case', 'spoon', 'sprinkled', 'polka-dotted', 'grid', 'buffet', 'kettle', 'marbled', 'stained', 'metal shutter', 'traveling bag', 'stage', 'hat', 'printer', 'gauzy', 'interlaced', 'blade', 'zigzagged', 'frilly', 'teapot', 'spiralled', 'swirly', 'chest', 'matted', 'cracked', 'studded', 'embankment', 'cloud', 'horn', 'flecked', 'potholed', 'stratified', 'braided', 'lined', 'scaly', 'paisley', 'wrinkled', 'waffled', 'freckled', 'honeycombed', 'document', 'office-s', 'rack', 'chequered', 'corridor-s', 'lacelike', 'crystalline', 'windows', 'bubbly', 'silver screen', 'pleated', 'cobwebbed', 'grooved', 'animal', 'pier', 'crane', 'fur', 'airport_terminal-s', 'tap', 'lower sash', 'statue', 'postbox', 'dome', 'dormer', 'wire', 'console table', 'rubber', 'trunk', 'game_room-s', 'camera', 'microphone', 'waiting_room-s', 'jacket', 'dishrag', 'poolroom-home-s', 'home_office-s', 'fountain', 'upper sash', 'paper towel', 'washer', 'partition', 'entrance', 'banner', 'runway', 'corner pocket', 'art_studio-s', 'tent', 'spindle', 'towel rack', 'attic-s', 'forest-broadleaf-s', 'park-s', 'mountain-s', 'waterfall', 'guitar', 'system', 'place mat', 'diffusor', 'foliage', 'bouquet', 'side rail', 'coast-s', 'booth', 'dirt track', 'vending machine', 'alley-s', 'deck chair', 'canister', 'hovel', 'skylight', 'helmet', 'telephone booth', 'net', 'shirt', 'parlor-s', 'cradle', 'candelabrum', 'closet-s', 'beach-s', 'easel', 'childs_room-s', 'art_gallery-s', 'cart', 'newspaper', 'cross', 'smoke', 'footbridge', 'casing', 'apartment_building-outdoor-s', 'arcade machine', 'machine', 'baby buggy', 'tank', 'shower stall', 'swimming pool', 'sales booth', 'scaffolding', 'sill', 'staircase-s', 'castle-s', 'fridge', 'patty', 'altar', 'pasture-s', 'streetcar', 'dorm_room-s', 'blackboard', 'tapestry', 'trouser', 'billboard', 'nursery-s', 'decoration', 'lobby-s', 'garage-indoor-s', 'reception-s', 'hot tub', 'garage door', 'file cabinet', 'drawing', 'piano', 'bar-s', 'conveyer belt', 'arcade', 'equipment', 'saucepan', 'forest-needleleaf-s', 'shaft', 'court', 'head roof', 'capital', 'bakery-shop-s', 'roundabout-s', 'warehouse-indoor-s', 'lake', 'barrel', 'ship', 'house-s', 'cage', 'railroad train', 'arch', 'lighthouse', 'bell', 'bus stop', 'exhibitor', 'jersey', 'plinth', 'forecourt', 'eiderdown', 'mat', 'cash register', 'casino-indoor-s', 'calendar', 'briefcase', 'field-cultivated-s', 'bridge-s', 'classroom-s', 'river-s', 'fire escape', 'mouse pad', 'cd', 'rocking chair', 'bread', 'youth_hostel-s', 'cliff', 'field-wild-s', 'escalator', 'fuselage', 'baseboard', 'lighthouse-s', 'clouds', 'elevator', 'table football', 'grand piano', 'earmuffs', 'creek-s', 'museum-indoor-s', 'shoe_shop-s', 'window_seat-s', 'scale', 'amusement_park-s', 'dinette-vehicle-s', 'vault', 'radio', 'lake-natural-s', 'dinette-home-s', 'riser', 'cockpit-s', 'fish', 'panel', 'tread', 'boot', 'stabilizer', 'jacuzzi-indoor-s', 'linoleum', 'dummy', 'playroom-s', 'mezzanine', 'fire place', 'map', 'menu', 'parking_lot-s', 'valley-s', 'rubbish', 'gym shoe', 'auditorium-s', 'beauty_salon-s', 'tower-s', 'slot machine', 'arcades', 'basketball hoop', 'wet_bar-s', 'artists_loft-s', 'tire', 'balcony-interior-s', 'video player', 'arrival_gate-outdoor-s', 'merchandise', 'television stand', 'playground-s', 'plaza-s', 'ice', 'playground', 'guardrail', 'hill-s', 'deck', 'table tennis', 'mattress', 'bidet', 'sweater', 'clothing_store-s', 'utility_room-s', 'bow_window-indoor-s', 'pantry-s', 'aircraft carrier', 'valley', 'railway', 'balloon', 'galley-s', 'bookstore-s', 'abbey-s', 'basement-s', 'pitch', 'display board', 'cockpit', 'pallet', 'supermarket-s', 'golf_course-s', 'patio', 'ad', 'price tag', 'coach roof', 'hallway-s', 'controls', 'island', 'metal shutters', 'laundromat-s', 'ballroom-s', 'greenhouse-indoor-s', 'gazebo-exterior-s', 'market-outdoor-s', 'subway_interior-s', 'curtains', 'porch', 'bottle rack', 'duck', 'gas pump', 'bus_interior-s', 'doorway-indoor-s', 'alcove-s', 'pulpit', 'ramp', 'access_road-s', 'landing_deck-s', 'archive-s', 'leaves', 'slope', 'helicopter', 'podium', 'steering wheel', 'finger', 'monument', 'trailer', 'gymnasium-indoor-s', 'waterfall-block-s', 'windmill', 'pool', 'water tower', 'folding screen', 'workbench', 'brushes', 'leaf', 'scoreboard', 'cathedral-indoor-s', 'office_building-s', 'baggage_claim-s', 'badlands-s', 'forest_path-s', 'home_theater-s', 'ocean-s', 'ice rink', 'carport', 'gravestone', 'straw', 'horse-drawn carriage', 'tunnel', 'cannon', 'tumble dryer', 'fastfood_restaurant-s', 'gas_station-s', 'church-indoor-s', 'harbor-s', 'amusement_arcade-s', 'poolroom-establishment-s', 'bowling_alley-s', 'auto_showroom-s', 'library-indoor-s', 'restaurant-s', 'toyshop-s', 'dentists_office-s', 'altarpiece', 'shelter', 'pond', 'windscreen', 'wheelchair', 'coat', 'planter', 'player', 'bow_window-outdoor-s', 'driveway-s', 'fairway-s', 'courthouse-s', 'yard-s', 'theater-indoor_procenium-s', 'parking_garage-indoor-s', 'construction_site-s', 'carousel', 'display window', 'elevator door', 'shop', 'roundabout', 'blinds', 'slide', 'amphitheater-s', 'ball_pit-s', 'desert-sand-s', 'control_tower-outdoor-s', 'cubicle-office-s', 'computer_room-s', 'kindergarden_classroom-s', 'water_tower-s', 'campus-s', 'airplane_cabin-s', 'music_studio-s', 'aquarium', 'ruins', 'instrument panel', 'ring', 'table game', 'television camera', 'control tower', 'goal', 'delicatessen-s', 'swimming_pool-outdoor-s', 'cloister-indoor-s', 'wine_cellar-barrel_storage-s', 'restaurant_patio-s', 'weighbridge-s', 'shopping_mall-indoor-s', 'berth-s', 'bird cage', 'aqueduct', 'weighbridge', 'bedpost', 'terrace', 'geodesic_dome-outdoor-s', 'swimming_pool-indoor-s', 'waterfall-fan-s', 'ice_skating_rink-indoor-s', 'cemetery-s', 'windmill-s', 'videostore-s', 'reading_room-s', 'folding door', 'stands', 'revolving door', 'mill', 'movie_theater-indoor-s', 'sauna-s', 'day_care_center-s', 'dining_car-s', 'jail_cell-s', 'mansion-s', 'courtroom-s', 'atrium-public-s', 'pantry', 'bandstand', 'videos', 'sand trap', 'organ', 'synthesizer', 'planks', 'pictures', 'parterre', 'doorway-outdoor-s', 'campsite-s', 'shower-s', 'florist_shop-indoor-s', 'hospital_room-s', 'inn-indoor-s', 'church-outdoor-s', 'lecture_room-s', 'mosque-outdoor-s', 'aqueduct-s', 'lockers', 'service station', 'trench', 'barrels', 'box office', 'binder', 'cabin', 'forklift', 'doors', 'pavilion', 'forest_road-s', 'cabin-outdoor-s', 'operating_room-s', 'inn-outdoor-s', 'greenhouse', 'caravan', 'berth', 'trellis', 'tomb', 'structure', 'plastic', 'parasol', 'sandbox-s', 'shopfront-s', 'planetarium-outdoor-s', 'snowfield-s', 'hayfield-s', 'carrousel-s', 'botanical_garden-s', 'barn-s', 'locker_room-s', 'crosswalk-s', 'television_studio-s', 'islet-s', 'slum-s', 'dam', 'tracks', 'hay', 'hen', 'recycling bin', 'disc case', 'diner-outdoor-s', 'ski_resort-s', 'monastery-outdoor-s', 'village-s', 'hunting_lodge-outdoor-s', 'marsh-s', 'fountain-s', 'subway_station-corridor-s', 'kitchenette-s', 'corn_field-s', 'kasbah-s', 'auto_factory-s', 'martial_arts_gym-s', 'balcony-exterior-s', 'courtyard-s', 'chicken_coop-outdoor-s', 'rope_bridge-s', 'shanties', 'wave', 'machinery', 'dashboard', 'dental chair', 'parking', 'sewing machine', 'rifle', 'kiosk-indoor-s', 'outhouse-outdoor-s', 'stage-indoor-s', 'art_school-s', 'viaduct-s', 'bleachers-outdoor-s', 'pulpit-s', 'garage-outdoor-s', 'corral-s', 'farm-s', 'baptistry-outdoor-s', 'wheat_field-s', 'arch-s', 'moor-s', 'hospital-s', 'runway-s', 'donjon-s', 'ruin-s', 'canyon-s', 'escalator-indoor-s', 'airport-s', 'desert', 'henhouse', 'tennis court', 'shed', 'bird feeder', 'washing machines', 'watchtower', 'shops', 'ride', 'telescope', 'slats', 'drum', 'fire', 'oar', 'breads', 'town_house-s', 'bank-outdoor-s', 'medina-s', 'candy_store-s', 'palace-s', 'mountain_path-s', 'fire_escape-s', 'dolmen-s', 'dacha-s', 'jail-indoor-s', 'car_interior-backseat-s', 'jewelry_shop-s', 'bus_depot-outdoor-s', 'embassy-s', 'elevator-interior-s', 'cavern-indoor-s', 'casino-outdoor-s', 'kennel-indoor-s', 'cathedral-outdoor-s', 'vegetable_garden-s', 'hot_spring-s', 'sandbar-s', 'observatory-outdoor-s', 'desert-vegetation-s', 'conference_center-s', 'covered_bridge-exterior-s', 'semidesert ground', 'grille door', 'roller coaster', 'water wheel', 'barbecue', 'bulldozer', 'steam shovel', 'gravel', 'meter', 'excavator', 'irrigation_ditch-s', 'dam-s', 'ranch_house-s', 'ranch-s', 'carport-outdoor-s', 'ghost_town-s', 'canal-urban-s', 'booth-indoor-s', 'hotel-outdoor-s', 'boxing_ring-s', 'stadium-baseball-s', 'fence-s', 'airport-entrance-s', 'excavation-s', 'ice_cream_parlor-s', 'student_residence-s', 'motel-s', 'sacristy-s', 'lift_bridge-s', 'junk_pile-s', 'hangar-indoor-s', 'flood-s', 'wrestling_ring-indoor-s', 'ski_slope-s', 'fitting_room-exterior-s', 'crevasse-s', 'elevator_lobby-s', 'estuary-s', 'bazaar-indoor-s', 'subway_station-platform-s', 'wine_cellar-bottle_storage-s', 'watchtower-s', 'kennel-outdoor-s', 'boathouse-s', 'greenhouse-outdoor-s', 'fitting_room-interior-s', 'vineyard-s', 'oast_house-s', 'moat-water-s', 'kiosk-outdoor-s', 'convenience_store-outdoor-s', 'nuclear_power_plant-outdoor-s', 'podium-indoor-s', 'orchard-s', 'movie_theater-outdoor-s', 'mountain_road-s', 'temple-east_asia-s', 'badminton_court-outdoor-s', 'vineyard', 'rubble', 'badlands', 'forest', 'ticket counter', 'stalls', 'shower curtain', 'village', 'safety side', 'gas station', 'niche', 'check-in-desk', 'set of instruments', 'bread rolls', 'coffee_shop-s', 'labyrinth-indoor-s', 'lawn-s', 'beach_house-s', 'escalator-outdoor-s', 'chalet-s', 'baseball_field-s', 'sun_deck-s', 'guardhouse-s', 'hut-s', 'flight_of_stairs-urban-s', 'waterfall-cascade-s', 'general_store-outdoor-s', 'mine-s', 'herb_garden-s', 'mosque-indoor-s', 'lagoon-s', 'topiary_garden-s', 'industrial_area-s', 'shed-s', 'pagoda-s', 'water_mill-s', 'elevator-door-s', 'cloister-outdoor-s', 'butchers_shop-s', 'apse-indoor-s', 'ice_skating_rink-outdoor-s', 'synagogue-outdoor-s', 'assembly_line-s', 'manufactured_home-s', 'firing_range-outdoor-s', 'barbershop-s', 'cottage_garden-s', 'hacienda-s', 'industrial_park-s', 'workshop-s', 'dugout-s', 'hat_shop-s', 'elevator-freight_elevator-s', 'spa-massage_room-s', 'savanna-s', 'bank-indoor-s', 'oasis-s', 'witness_stand-s', 'road_cut-s', 'volleyball_court-outdoor-s', 'anechoic_chamber-s', 'train_station-outdoor-s', 'canal-natural-s', 'parking_garage-outdoor-s', 'food_court-s', 'downtown-s', 'driving_range-outdoor-s', 'catwalk-s', 'market-indoor-s', 'carport-freestanding-s', 'elevator_shaft-s', 'moon_bounce-s', 'formal_garden-s', 'cargo_container_interior-s', 'bog-s', 'airport_ticket_counter-s', 'lido_deck-outdoor-s', 'military_hut-s', 'baptistry-indoor-s', 'bullring-s', 'library-outdoor-s', 'inflatable bounce game', 'temple', 'bowling alley', 'mosque', 'skittle alley', 'sandbox', 'catwalk', 'big top', 'iceberg', 'viaduct', 'fog bank', 'parking lot', 'trestle', 'table cloth', 'tables', 'pigeonhole', 'cactus', 'bathrobe', 'rudder', 'crate', 'quay', 'hand cart', 'candies', 'control_tower-indoor-s', 'mausoleum-s', 'liquor_store-indoor-s', 'choir_loft-exterior-s', 'chapel-s', 'jacuzzi-outdoor-s', 'hot_tub-outdoor-s', 'imaret-s', 'heliport-s', 'dirt_track-s', 'batters_box-s', 'quadrangle-s', 'liquor_store-outdoor-s', 'bazaar-outdoor-s', 'hoodoo-s', 'dining_hall-s', 'banquet_hall-s', 'basketball_court-outdoor-s', 'gulch-s', 'granary-s', 'pilothouse-indoor-s', 'natural_history_museum-s', 'bakery-kitchen-s', 'cottage-s', 'cabana-s', 'landing-s', 'signal_box-s', 'checkout_counter-s', 'labyrinth-outdoor-s', 'bus_shelter-s', 'zen_garden-s', 'fishpond-s', 'gift_shop-s', 'watering_hole-s', 'hot_tub-indoor-s', 'call_center-s', 'air_base-s', 'manhole-s', 'joss_house-s', 'badminton_court-indoor-s', 'fjord-s', 'limousine_interior-s', 'backstairs-s', 'moat-dry-s', 'cardroom-s', 'brewery-outdoor-s', 'loading_dock-s', 'clean_room-s', 'convenience_store-indoor-s', 'barnyard-s', 'car_dealership-s', 'tearoom-s', 'museum-outdoor-s', 'fire_station-s', 'bedchamber-s', 'bistro-indoor-s', 'butte-s', 'field_road-s', 'rubble-s', 'hedge_maze-s', 'flight_of_stairs-natural-s', 'aquatic_theater-s', 'mission-s', 'lean-to-s', 'basketball_court-indoor-s', 'newsstand-outdoor-s', 'football_field-s', 'freeway-s', 'hangar-outdoor-s', 'cafeteria-s', 'building_complex-s', 'covered_bridge-interior-s', 'bayou-s', 'throne_room-s', 'hunting_lodge-indoor-s', 'funeral_chapel-s', 'beer_garden-s', 'bullpen-s', 'archaelogical_excavation-s', 'junkyard-s', 'bank_vault-s', 'cheese_factory-s', 'lake-artificial-s', 'florist_shop-outdoor-s', 'hotel_breakfast_area-s', 'canteen-s', 'catacomb-s', 'drainage_ditch-s', 'auto_mechanics-indoor-s', 'bleachers-indoor-s', 'nunnery-s', 'earth_fissure-s', 'japanese_garden-s', 'fort-s', 'circus_tent-outdoor-s', 'jail-outdoor-s', 'pub-outdoor-s', 'cubicle-library-s', 'labyrinth', 'bullring', 'terraces', 'acropolis', 'covered bridge', 'shipyard', 'ticket window', 'elephant', 'toll booth', 'book stand', 'skeleton', 'baptismal font', 'witness stand', 'vegetables', 'mountain pass', 'meat', 'canvas', 'shore']\n",
      "['color', 'object', 'part', 'material', 'scene', 'texture']\n",
      "[5 0 0 ..., 1 1 1]\n"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "\n",
    "generator = torch.load(\"gen_mnist_model_epoch_200.pt\", map_location='cpu')\n",
    "print(generator)\n",
    "# generater.load_state_dict(torch.load(\".sample_data/gen_mnist_model_epoch_200.pt\", map_location='cpu'))\n",
    "# generater.eval()\n"
=======
    "segments = 'quick-netdissect/dataset/broden'\n",
    "imgsize = (227, 227)\n",
    "broden_version = 1\n",
    "perturbation = None\n",
    "download = False\n",
    "size = 10000\n",
    "\n",
    "# Load broden dataset\n",
    "ds = try_to_load_broden(segments, imgsize, broden_version, perturbation, download, size)\n",
    "\n",
    "if ds is None:\n",
    "    ds = try_to_load_multiseg(segments, imgsize,perturbation, size)\n",
    "\n",
    "print(ds.labels)\n",
    "print(ds.categories)\n",
    "print(ds.label_category)"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
>>>>>>> 48b6c627ed647b6b208018ad087189a95b7f8627
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "PTWwHQA2tnxM"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "\n",
    "def get_multi_mnist_dataloaders(batch_size=128):\n",
    "    # Resize images so they are a power of 2\n",
    "    all_transforms = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "#         transforms.Resize(32),\n",
    "        transforms.Resize(100),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_data = MultiMNIST('MNIST_synthetic.h5',  train = True, transform = all_transforms)\n",
    "    test_data = MultiMNIST('MNIST_synthetic.h5', train = False, transform = all_transforms)\n",
    "\n",
    "    # Create dataloaders\n",
    "#     train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "#     test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "#     return train_loader, test_loader\n",
    "    return train_data, test_data\n",
    "\n",
    "class MultiMNIST(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, path = 'MNIST_synthetic.h5', train = True, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        super(MultiMNIST, self).__init__()\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "        f = h5py.File(self.path, 'r')\n",
    "\n",
    "        if train:\n",
    "            self.X = list(f['train_dataset'])\n",
    "            self.y = list(f['train_labels'])\n",
    "            self.seg = list(f['train_segmentations'])\n",
    "\n",
    "        else:\n",
    "            self.X = list(f['test_dataset'])\n",
    "            self.y = list(f['test_labels'])\n",
    "            self.seg = list(f['test_segmentations'])\n",
    "\n",
    "        if False:\n",
    "            self.X = list(f['val_dataset'])\n",
    "            self.y = list(f['val_labels'])\n",
    "            self.seg = list(f['val_segmentations'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "#     def __iter__(self):\n",
    "#         return DataLoaderIter(self)\n",
    "\n",
    "    def __getitem__(self, index):#, seg=False):\n",
    "\n",
    "        img = self.X[index]\n",
    "        target = self.y[index]\n",
    "        seg = self.seg[index]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target, seg"
=======
   "execution_count": 6,
>>>>>>> 48b6c627ed647b6b208018ad087189a95b7f8627
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGE_STDEV = [0.229, 0.224, 0.225]\n",
    "\n",
    "\"\"\"\n",
    "bds = BrodenDataset(directory='quick-netdissect/dataset/broden',broden_version=1,download=False,resolution=227,\n",
    "                   transform_image=transforms.Compose([\n",
    "                        transforms.Resize(224),\n",
<<<<<<< HEAD
    "                        transforms.ToTensor()]))\n",
    "\n",
    "\"\"\"\n",
    "bds = MultiMNIST(path = 'data/multi_mnist/MNIST_synthetic_31_3.h5',train = True, \n",
    "                 transform= transforms.Compose([\n",
    "                        transforms.Resize(224),\n",
    "                        transforms.ToTensor()]))\n",
    "\n"
=======
    "                        transforms.ToTensor()]))"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sxcFUhfCg3pG"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'netdissect'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f53c5317ad50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnetdissect\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mretain_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdissect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnetdissect\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mReverseNormalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'netdissect'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from netdissect import retain_layers, dissect\n",
    "from netdissect import ReverseNormalize\n",
    "\n",
    "generator.eval()\n",
    "generator.cuda()\n",
    "  \n",
    "#   for name, layer in generator.named_modules():\n",
    "#     print(name)\n",
    "#============ result: \n",
    "# latent_to_features\n",
    "# latent_to_features.0\n",
    "# latent_to_features.1\n",
    "# features_to_image\n",
    "# features_to_image.0\n",
    "# features_to_image.1\n",
    "# features_to_image.2\n",
    "# features_to_image.3\n",
    "# features_to_image.4\n",
    "# features_to_image.5\n",
    "# features_to_image.6\n",
    "# features_to_image.7\n",
    "# features_to_image.8\n",
    "# features_to_image.9\n",
    "# features_to_image.10\n",
    "\n",
    "retain_layers(generator, ['features_to_image.0',\n",
    "                          'features_to_image.1', \n",
    "                          'features_to_image.2', \n",
    "                          'features_to_image.3', \n",
    "                          'features_to_image.4',\n",
    "                          'features_to_image.5',\n",
    "                          'features_to_image.6',\n",
    "                          'features_to_image.7',\n",
    "                          'features_to_image.8',\n",
    "                          'features_to_image.9',\n",
    "                          'features_to_image.10'])\n",
    "bds, _ = get_multi_mnist_dataloaders()\n",
    "dissect('sample_data/', generator, bds,\n",
    "        recover_image=ReverseNormalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        batch_size=100,\n",
    "        examples_per_unit=10)\n"
>>>>>>> 48b6c627ed647b6b208018ad087189a95b7f8627
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bds.categories\n",
    "#bds.category_info\n",
    "#bds.category_label\n",
    "#bds.category_map\n",
    "#bds.directory\n",
    "#bds.image\n",
    "#bds.include_bincount\n",
    "#bds.label_category\n",
    "#bds.label_info\n",
    "#bds.labels\n",
    "#bds.loader\n",
    "#bds.max_segment_depth\n",
    "#bds.num_labels\n",
    "#bds.resdir\n",
    "#bds.resolution\n",
    "#bds.transform_image\n",
    "#bds.transform_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'netdissect'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f15feeea1511>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnetdissect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'netdissect'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    " import netdissect"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sw': 32, 'digit': ['img/001000.png'], 'ih': 64, 'iw': 64, 'sh': 32, 'image': 'img/001000.png'}\n",
      "255\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 1000\n",
    "print(bds.image[i])\n",
    "im_name = bds.resdir + bds.image[i]['image']\n",
    "color_name = bds.resdir + bds.image[i]['digit'][0]\n",
    "\n",
    "#print(os.path.exists('quick-netdissect/dataset/broden/broden1_227/images/'))\n",
    "im = cv2.imread(im_name)\n",
    "\n",
    "print(np.max(im))\n",
    "#print(im)\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "color_im = cv2.imread(color_name)\n",
    "print(np.min(color_im),np.max(color_im))\n",
    "\n",
    "material_im = cv2.imread(material_name)\n",
    "print(np.min(material_im),np.max(material_im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are startingg!\n",
      " segloader!!!\n",
      "collect stuff\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7705d34b1b4e85957032e48864b7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Quantiles', max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Traceback (most recent call last):\n  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-56-6cec540cb184>\", line 166, in __getitem__\n    img = self.transform_image(img)\n  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/torchvision-0.2.1-py3.5.egg/torchvision/transforms/transforms.py\", line 49, in __call__\n    img = t(img)\n  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/torchvision-0.2.1-py3.5.egg/torchvision/transforms/transforms.py\", line 175, in __call__\n    return F.resize(img, self.size, self.interpolation)\n  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/torchvision-0.2.1-py3.5.egg/torchvision/transforms/functional.py\", line 189, in resize\n    raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\nTypeError: img should be PIL Image. Got <class 'numpy.ndarray'>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-b65f18fe5a2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mrecover_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mReverseNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_MEAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_STDEV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         examples_per_unit=1)\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/quick-netdissect/netdissect/dissection.py\u001b[0m in \u001b[0;36mdissect\u001b[0;34m(outdir, model, dataset, recover_image, quantile_threshold, iou_threshold, examples_per_unit, batch_size, num_workers, make_images, make_labels, make_report, make_single_images, netname, meta, settings)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"collect stuff\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mquantiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_quantiles_and_topk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecover_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecover_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexamples_per_unit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"levels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/quick-netdissect/netdissect/dissection.py\u001b[0m in \u001b[0;36mcollect_quantiles_and_topk\u001b[0;34m(model, segloader, recover_image, k, resolution)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0mprogress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Quantiles'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m         \u001b[0;31m# We don't actually care about the model output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.5/site-packages/tqdm/_tqdm_notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.5/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyspark/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Traceback (most recent call last):\n  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-56-6cec540cb184>\", line 166, in __getitem__\n    img = self.transform_image(img)\n  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/torchvision-0.2.1-py3.5.egg/torchvision/transforms/transforms.py\", line 49, in __call__\n    img = t(img)\n  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/torchvision-0.2.1-py3.5.egg/torchvision/transforms/transforms.py\", line 175, in __call__\n    return F.resize(img, self.size, self.interpolation)\n  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/torchvision-0.2.1-py3.5.egg/torchvision/transforms/functional.py\", line 189, in resize\n    raise TypeError('img should be PIL Image. Got {}'.format(type(img)))\nTypeError: img should be PIL Image. Got <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "dissect('result/dissect', model, bds,\n",
    "        recover_image=ReverseNormalize(IMAGE_MEAN, IMAGE_STDEV),\n",
<<<<<<< HEAD
    "        batch_size=1,\n",
    "        examples_per_unit=1)"
=======
    "        examples_per_unit=10)"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
>>>>>>> 48b6c627ed647b6b208018ad087189a95b7f8627
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3rpC_C88qsv7"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WVqROMVQqiHc"
   },
=======
   "metadata": {},
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
   "outputs": [],
   "source": [
    "PIL.open"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "dissect_MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
=======
   "display_name": "Python (pyspark)",
   "language": "python",
   "name": "pyspark"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.6.8"
=======
   "version": "3.5.6"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
