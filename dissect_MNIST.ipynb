{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301.0
    },
    "colab_type": "code",
    "id": "i_sBdOspr-zL",
    "outputId": "f1e4681e-8a87-4db7-a15a-3d191636249e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting netdissect from git+git://github.com/davidbau/quick-netdissect.git#egg=netdissect\n",
      "  Cloning git://github.com/davidbau/quick-netdissect.git to c:\\users\\lucy\\appdata\\local\\temp\\pip-build-mv64krpi\\netdissect\n",
      "fatal: unable to connect to github.com:\n",
      "github.com[0: 192.30.255.112]: errno=Invalid argument\n",
      "github.com[1: 192.30.255.113]: errno=Invalid argument\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command \"git clone -q git://github.com/davidbau/quick-netdissect.git C:\\Users\\Lucy\\AppData\\Local\\Temp\\pip-build-mv64krpi\\netdissect\" failed with error code 128 in None\n",
      "You are using pip version 9.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+git://github.com/davidbau/quick-netdissect.git#egg=netdissect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "colab_type": "code",
    "id": "qdRVoamxCyUF",
    "outputId": "6eafacf9-4ed4-467a-da16-a6c1173b9a96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\lucy\\anaconda3\\lib\\site-packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "outputs": [],
   "source": [
    "<a href=\"https://colab.research.google.com/github/FrederikWarburg/CS-294-131-Trustworthy-Deep-Learning/blob/master/dissect_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qmLgm0-vs6sk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, img_size, latent_dim, dim):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_size = img_size\n",
    "        self.feature_sizes = int(self.img_size[0] / 16), int(self.img_size[1] / 16)\n",
    "\n",
    "        self.latent_to_features = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 8 * dim * self.feature_sizes[0] * self.feature_sizes[1]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.features_to_image = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8 * dim, 4 * dim, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(4 * dim),\n",
    "            nn.ConvTranspose2d(4 * dim, 2 * dim, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(2 * dim),\n",
    "            nn.ConvTranspose2d(2 * dim, dim, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(dim),\n",
    "            nn.ConvTranspose2d(dim, self.img_size[2], 4, 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # Map latent into appropriate size for transposed convolutions\n",
    "        x = self.latent_to_features(input_data)\n",
    "        # Reshape\n",
    "        x = x.view(-1, 8 * self.dim, self.feature_sizes[0], self.feature_sizes[1])\n",
    "        # Return generated image\n",
    "        return self.features_to_image(x)\n",
    "\n",
    "    def sample_latent(self, num_samples):\n",
    "        return torch.randn((num_samples, self.latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355.0
    },
    "colab_type": "code",
    "id": "AyDPTFay_xOO",
    "outputId": "76ced54a-5a14-490e-a2d8-9ec64afd130e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (latent_to_features): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (features_to_image): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ConvTranspose2d(16, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generator = torch.load(\"gen_mnist_model_epoch_200.pt\", map_location='cpu')\n",
    "print(generator)\n",
    "# generater.load_state_dict(torch.load(\".sample_data/gen_mnist_model_epoch_200.pt\", map_location='cpu'))\n",
    "# generater.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "PTWwHQA2tnxM"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "\n",
    "def get_multi_mnist_dataloaders(batch_size=128):\n",
    "    # Resize images so they are a power of 2\n",
    "    all_transforms = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "#         transforms.Resize(32),\n",
    "        transforms.Resize(100),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_data = MultiMNIST('MNIST_synthetic.h5',  train = True, transform = all_transforms)\n",
    "    test_data = MultiMNIST('MNIST_synthetic.h5', train = False, transform = all_transforms)\n",
    "\n",
    "    # Create dataloaders\n",
    "#     train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "#     test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "#     return train_loader, test_loader\n",
    "    return train_data, test_data\n",
    "\n",
    "class MultiMNIST(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, path = 'MNIST_synthetic.h5', train = True, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        super(MultiMNIST, self).__init__()\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "        f = h5py.File(self.path, 'r')\n",
    "\n",
    "        if train:\n",
    "            self.X = list(f['train_dataset'])\n",
    "            self.y = list(f['train_labels'])\n",
    "            self.seg = list(f['train_segmentations'])\n",
    "\n",
    "        else:\n",
    "            self.X = list(f['test_dataset'])\n",
    "            self.y = list(f['test_labels'])\n",
    "            self.seg = list(f['test_segmentations'])\n",
    "\n",
    "        if False:\n",
    "            self.X = list(f['val_dataset'])\n",
    "            self.y = list(f['val_labels'])\n",
    "            self.seg = list(f['val_segmentations'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "#     def __iter__(self):\n",
    "#         return DataLoaderIter(self)\n",
    "\n",
    "    def __getitem__(self, index):#, seg=False):\n",
    "\n",
    "        img = self.X[index]\n",
    "        target = self.y[index]\n",
    "        seg = self.seg[index]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target, seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sxcFUhfCg3pG"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'netdissect'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f53c5317ad50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnetdissect\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mretain_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdissect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnetdissect\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mReverseNormalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'netdissect'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from netdissect import retain_layers, dissect\n",
    "from netdissect import ReverseNormalize\n",
    "\n",
    "generator.eval()\n",
    "generator.cuda()\n",
    "  \n",
    "#   for name, layer in generator.named_modules():\n",
    "#     print(name)\n",
    "#============ result: \n",
    "# latent_to_features\n",
    "# latent_to_features.0\n",
    "# latent_to_features.1\n",
    "# features_to_image\n",
    "# features_to_image.0\n",
    "# features_to_image.1\n",
    "# features_to_image.2\n",
    "# features_to_image.3\n",
    "# features_to_image.4\n",
    "# features_to_image.5\n",
    "# features_to_image.6\n",
    "# features_to_image.7\n",
    "# features_to_image.8\n",
    "# features_to_image.9\n",
    "# features_to_image.10\n",
    "\n",
    "retain_layers(generator, ['features_to_image.0',\n",
    "                          'features_to_image.1', \n",
    "                          'features_to_image.2', \n",
    "                          'features_to_image.3', \n",
    "                          'features_to_image.4',\n",
    "                          'features_to_image.5',\n",
    "                          'features_to_image.6',\n",
    "                          'features_to_image.7',\n",
    "                          'features_to_image.8',\n",
    "                          'features_to_image.9',\n",
    "                          'features_to_image.10'])\n",
    "bds, _ = get_multi_mnist_dataloaders()\n",
    "dissect('sample_data/', generator, bds,\n",
    "        recover_image=ReverseNormalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        batch_size=100,\n",
    "        examples_per_unit=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'netdissect'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f15feeea1511>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnetdissect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'netdissect'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    " import netdissect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3rpC_C88qsv7"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WVqROMVQqiHc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "dissect_MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
