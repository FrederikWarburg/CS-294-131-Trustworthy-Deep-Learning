{
 "cells": [
  {
<<<<<<< HEAD
=======
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FrederikWarburg/CS-294-131-Trustworthy-Deep-Learning/blob/master/dissect_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
<<<<<<< HEAD
     "height": 301.0
    },
    "colab_type": "code",
    "id": "i_sBdOspr-zL",
    "outputId": "f1e4681e-8a87-4db7-a15a-3d191636249e"
=======
     "height": 301
    },
    "colab_type": "code",
    "id": "i_sBdOspr-zL",
    "outputId": "f1e4681e-8a87-4db7-a15a-3d191636249e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting netdissect from git+git://github.com/davidbau/quick-netdissect.git#egg=netdissect\n",
      "  Cloning git://github.com/davidbau/quick-netdissect.git to /tmp/pip-install-fq4hn8gl/netdissect\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from netdissect) (1.14.6)\n",
      "Requirement already satisfied: Pillow>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from netdissect) (4.1.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from netdissect) (1.1.0)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from netdissect) (1.0.1.post2)\n",
      "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from netdissect) (0.2.2.post3)\n",
      "Requirement already satisfied: tqdm>=4.23.4 in /usr/local/lib/python3.6/dist-packages (from netdissect) (4.28.1)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow>=4.1.0->netdissect) (0.46)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->netdissect) (1.11.0)\n",
      "Building wheels for collected packages: netdissect\n",
      "  Building wheel for netdissect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-q5v5u7h6/wheels/95/03/aa/c38949a7269a6ee2f0ceb9e98b54e67fc7f9bfc5b47d1c5e4f\n",
      "Successfully built netdissect\n",
      "Installing collected packages: netdissect\n",
      "Successfully installed netdissect-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install git+git://github.com/davidbau/quick-netdissect.git#egg=netdissect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1.post2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qdRVoamxCyUF",
    "outputId": "6eafacf9-4ed4-467a-da16-a6c1173b9a96"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Collecting netdissect from git+git://github.com/davidbau/quick-netdissect.git#egg=netdissect\n",
      "  Cloning git://github.com/davidbau/quick-netdissect.git to c:\\users\\lucy\\appdata\\local\\temp\\pip-build-mv64krpi\\netdissect\n",
      "fatal: unable to connect to github.com:\n",
      "github.com[0: 192.30.255.112]: errno=Invalid argument\n",
      "github.com[1: 192.30.255.113]: errno=Invalid argument\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command \"git clone -q git://github.com/davidbau/quick-netdissect.git C:\\Users\\Lucy\\AppData\\Local\\Temp\\pip-build-mv64krpi\\netdissect\" failed with error code 128 in None\n",
      "You are using pip version 9.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+git://github.com/davidbau/quick-netdissect.git#egg=netdissect"
=======
      "Requirement already satisfied: torch in /Users/frederikwarburg/anaconda3/lib/python3.6/site-packages (1.0.1.post2)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python35.zip',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/plat-darwin',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/lib-dynload',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/torchvision-0.2.1-py3.5.egg',\n",
       " '/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/site-packages/IPython/extensions',\n",
       " '/Users/frederikwarburg/.ipython',\n",
       " '/Users/frederikwarburg/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/wgan-gp/',\n",
       " '/Users/frederikwarburg/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/quick-netdissect/']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/wgan-gp/\")\n",
    "sys.path.append(os.getcwd() + \"/quick-netdissect/\")\n",
    "sys.path"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "colab_type": "code",
    "id": "qdRVoamxCyUF",
    "outputId": "6eafacf9-4ed4-467a-da16-a6c1173b9a96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\lucy\\anaconda3\\lib\\site-packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
=======
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "colab_type": "code",
    "id": "AyDPTFay_xOO",
    "outputId": "76ced54a-5a14-490e-a2d8-9ec64afd130e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (latent_to_features): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (features_to_image): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ConvTranspose2d(16, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generator = torch.load(\"wgan-gp/mnist_models/gen_mnist_model_epoch_200.pt\", map_location='cpu')\n",
    "print(generator)\n",
    "# generater.load_state_dict(torch.load(\".sample_data/gen_mnist_model_epoch_200.pt\", map_location='cpu'))\n",
    "# generater.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PTWwHQA2tnxM"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "\n",
    "def get_multi_mnist_dataloaders(batch_size=128):\n",
    "    # Resize images so they are a power of 2\n",
    "    all_transforms = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "#         transforms.Resize(32),\n",
    "        transforms.Resize(100),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_data = MultiMNIST('data/multi_mnist/MNIST_synthetic_31_3.h5',  train = True, transform = all_transforms)\n",
    "    test_data = MultiMNIST('data/multi_mnist/MNIST_synthetic_31_3.h5', train = False, transform = all_transforms)\n",
    "\n",
    "    # Create dataloaders\n",
    "#     train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "#     test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "#     return train_loader, test_loader\n",
    "    return train_data, test_data\n",
    "\n",
    "class MultiMNIST(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, path = 'data/multi_mnist/MNIST_synthetic_31_3.h5', train = True, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        super(MultiMNIST, self).__init__()\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "        f = h5py.File(self.path, 'r')\n",
    "\n",
    "        if train:\n",
    "            self.X = list(f['train_dataset'])\n",
    "            self.y = list(f['train_labels'])\n",
    "            self.seg = list(f['train_segmentations'])\n",
    "\n",
    "        else:\n",
    "            self.X = list(f['test_dataset'])\n",
    "            self.y = list(f['test_labels'])\n",
    "            self.seg = list(f['test_segmentations'])\n",
    "\n",
    "        if False:\n",
    "            self.X = list(f['val_dataset'])\n",
    "            self.y = list(f['val_labels'])\n",
    "            self.seg = list(f['val_segmentations'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "#     def __iter__(self):\n",
    "#         return DataLoaderIter(self)\n",
    "\n",
    "    def __getitem__(self, index):#, seg=False):\n",
    "\n",
    "        img = self.X[index]\n",
    "        target = self.y[index]\n",
    "        seg = self.seg[index]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target, seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sxcFUhfCg3pG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/frederikwarburg/anaconda3/envs/pyspark/lib/python3.5/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-74de346835c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mrecover_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mReverseNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         examples_per_unit=10)\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/quick-netdissect/netdissect/dissection.py\u001b[0m in \u001b[0;36mdissect\u001b[0;34m(outdir, model, dataset, recover_image, quantile_threshold, iou_threshold, examples_per_unit, batch_size, num_workers, make_images, make_labels, make_report, make_single_images, netname, meta, settings)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 pin_memory=(device.type == 'cuda'))\n\u001b[1;32m     71\u001b[0m         quantiles, topk = collect_quantiles_and_topk(model, segloader,\n\u001b[0;32m---> 72\u001b[0;31m                 recover_image=recover_image, k=examples_per_unit)\n\u001b[0m\u001b[1;32m     73\u001b[0m         levels = {k: qc.quantiles([1.0 - quantile_threshold])[:,0]\n\u001b[1;32m     74\u001b[0m                 for k, qc in quantiles.items()}\n",
      "\u001b[0;32m~/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/quick-netdissect/netdissect/dissection.py\u001b[0m in \u001b[0;36mcollect_quantiles_and_topk\u001b[0;34m(model, segloader, recover_image, k, resolution)\u001b[0m\n\u001b[1;32m    393\u001b[0m                         \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                         ).contiguous().view(-1, value.shape[1])\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mquantiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mtopks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mquantiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/quick-netdissect/netdissect/runningstats.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, incoming)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# Convert to a flat torch array.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_every\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincoming\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# If we are sampling, then subsample a large chunk at a time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/quick-netdissect/netdissect/runningstats.py\u001b[0m in \u001b[0;36m_add_every\u001b[0;34m(self, incoming)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mavailable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mavailable\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m                     \u001b[0;31m# If we shifted by subsampling, then subsample.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0mincoming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mincoming\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/quick-netdissect/netdissect/runningstats.py\u001b[0m in \u001b[0;36m_shift\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirstfree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_extremes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "!pip install torch"
=======
    "from netdissect import retain_layers, dissect\n",
    "from netdissect import ReverseNormalize\n",
    "i\n",
    "\n",
    "generator.eval()\n",
    "#generator.cuda()\n",
    "  \n",
    "#   for name, layer in generator.named_modules():\n",
    "#     print(name)\n",
    "#============ result: \n",
    "# latent_to_features\n",
    "# latent_to_features.0\n",
    "# latent_to_features.1\n",
    "# features_to_image\n",
    "# features_to_image.0\n",
    "# features_to_image.1\n",
    "# features_to_image.2\n",
    "# features_to_image.3\n",
    "# features_to_image.4\n",
    "# features_to_image.5\n",
    "# features_to_image.6\n",
    "# features_to_image.7\n",
    "# features_to_image.8\n",
    "# features_to_image.9\n",
    "# features_to_image.10\n",
    "\n",
    "retain_layers(generator, ['features_to_image.0',\n",
    "                          'features_to_image.1', \n",
    "                          'features_to_image.2', \n",
    "                          'features_to_image.3', \n",
    "                          'features_to_image.4',\n",
    "                          'features_to_image.5',\n",
    "                          'features_to_image.6',\n",
    "                          'features_to_image.7',\n",
    "                          'features_to_image.8',\n",
    "                          'features_to_image.9',\n",
    "                          'features_to_image.10'])\n",
    "bds, _ = get_multi_mnist_dataloaders()\n",
    "\n",
    "dissect('sample_data/', generator, bds,\n",
    "        recover_image=ReverseNormalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        batch_size=100,\n",
    "        examples_per_unit=10)\n"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "outputs": [],
   "source": [
    "<a href=\"https://colab.research.google.com/github/FrederikWarburg/CS-294-131-Trustworthy-Deep-Learning/blob/master/dissect_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
=======
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/wgan-gp/\")\n",
    "sys.path.append(os.getcwd() + \"/quick-netdissect/\")\n",
    "sys.path\n",
    "\n",
    "import torch\n",
    "from netdissect import retain_layers, dissect\n",
    "from netdissect import ReverseNormalize\n",
    "import torchvision.models as models\n",
    "from netdissect import BrodenDataset\n",
    "from netdissect.progress import verbose_progress\n",
    "verbose_progress(True)\n",
    "from torchvision.models import alexnet\n",
    "from torchvision import transforms"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "qmLgm0-vs6sk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, img_size, latent_dim, dim):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_size = img_size\n",
    "        self.feature_sizes = int(self.img_size[0] / 16), int(self.img_size[1] / 16)\n",
    "\n",
    "        self.latent_to_features = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 8 * dim * self.feature_sizes[0] * self.feature_sizes[1]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.features_to_image = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8 * dim, 4 * dim, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(4 * dim),\n",
    "            nn.ConvTranspose2d(4 * dim, 2 * dim, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(2 * dim),\n",
    "            nn.ConvTranspose2d(2 * dim, dim, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(dim),\n",
    "            nn.ConvTranspose2d(dim, self.img_size[2], 4, 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # Map latent into appropriate size for transposed convolutions\n",
    "        x = self.latent_to_features(input_data)\n",
    "        # Reshape\n",
    "        x = x.view(-1, 8 * self.dim, self.feature_sizes[0], self.feature_sizes[1])\n",
    "        # Return generated image\n",
    "        return self.features_to_image(x)\n",
    "\n",
    "    def sample_latent(self, num_samples):\n",
    "        return torch.randn((num_samples, self.latent_dim))"
=======
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3rpC_C88qsv7"
   },
   "outputs": [],
   "source": [
    "def eval_constructor(term, construct_types=True):\n",
    "    '''\n",
    "    Used to evaluate an arbitrary command-line constructor specifying\n",
    "    a class, with automatic import of global module names.\n",
    "    '''\n",
    "    from collections import defaultdict\n",
    "    from importlib import import_module\n",
    "\n",
    "    class DictNamespace(object):\n",
    "        def __init__(self, d):\n",
    "            self.__d__ = d\n",
    "        def __getattr__(self, key):\n",
    "            return self.__d__[key]\n",
    "\n",
    "    class AutoImportDict(defaultdict):\n",
    "        def __init__(self, parent=None):\n",
    "            super().__init__()\n",
    "            self.parent = parent\n",
    "        def __missing__(self, key):\n",
    "            if self.parent is not None:\n",
    "                key = self.parent + '.' + key\n",
    "            if hasattr(__builtins__, key):\n",
    "                return getattr(__builtins__, key)\n",
    "            mdl = import_module(key)\n",
    "            # Return an AutoImportDict for any namespace packages\n",
    "            if hasattr(mdl, '__path__') and not hasattr(mdl, '__file__'):\n",
    "                return DictNamespace(AutoImportDict(key))\n",
    "            return mdl\n",
    "\n",
    "    obj = eval(term, {}, AutoImportDict())\n",
    "    if isinstance(obj, type):\n",
    "        obj = obj()\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WVqROMVQqiHc"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = eval_constructor('torchvision.models.alexnet(pretrained=True)')\n",
    "model.eval()\n",
    "\n",
    "retain_layers(model, [\n",
    "        ('features.0', 'conv1'),\n",
    "        ('features.3', 'conv2'),\n",
    "        ('features.6', 'conv3'),\n",
    "        ('features.8', 'conv4'),\n",
    "        ('features.10', 'conv5') ])\n",
    "\n",
    "\n"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
<<<<<<< HEAD
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355.0
    },
    "colab_type": "code",
    "id": "AyDPTFay_xOO",
    "outputId": "76ced54a-5a14-490e-a2d8-9ec64afd130e"
   },
=======
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_to_load_broden(directory, imgsize, broden_version, perturbation,\n",
    "        download, size):\n",
    "    # Load broden dataset\n",
    "    ds_resolution = (224 if max(imgsize) <= 224 else\n",
    "                     227 if max(imgsize) <= 227 else 384)\n",
    "    if not os.path.isfile(os.path.join(directory, 'broden%d_%d' % (broden_version, ds_resolution), 'index.csv')):\n",
    "        return None\n",
    "    \n",
    "    print(directory,\n",
    "            ds_resolution,\n",
    "            download,\n",
    "            broden_version)\n",
    "    return BrodenDataset(directory,\n",
    "            resolution=ds_resolution,\n",
    "            download=download,\n",
    "            broden_version=broden_version)\n",
    "\n",
    "def try_to_load_multiseg(directory, imgsize, perturbation, size):\n",
    "    if not os.path.isfile(os.path.join(directory, 'labelnames.json')):\n",
    "        return None\n",
    "    minsize = min(imgsize) if hasattr(imgsize, '__iter__') else imgsize\n",
    "    return MultiSegmentDataset(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Generator(\n",
      "  (latent_to_features): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (features_to_image): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ConvTranspose2d(16, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      ")\n"
=======
      "quick-netdissect/dataset/broden 227 False 1\n",
      "['', 'black-c', 'grey-c', 'white-c', 'brown-c', 'green-c', 'pink-c', 'purple-c', 'blue-c', 'yellow-c', 'red-c', 'orange-c', 'wall', 'sky', 'floor', 'windowpane', 'tree', 'wood', 'building', 'person', 'painted', 'head', 'leg', 'door', 'fabric', 'ceiling', 'torso', 'table', 'arm', 'eye', 'glass', 'road', 'ear', 'grass', 'metal', 'plant', 'chair', 'nose', 'car', 'neck', 'painting', 'carpet', 'hand', 'sidewalk', 'wheel', 'cabinet', 'light', 'signboard', 'mirror', 'tile', 'lamp', 'hair', 'ground', 'mouth', 'curtain', 'pole', 'mountain', 'fence', 'foot', 'street-s', 'streetlight', 'bed', 'eyebrow', 'sofa', 'handle', 'box', 'tail', 'muzzle', 'earth', 'plastic-opaque', 'bottle', 'paper', 'shelf', 'headlight', 'drawer', 'water', 'railing', 'cushion', 'book', 'flower', 'granite', 'back', 'shade', 'bedroom-s', 'ceramic', 'rock', 'seat', 'paw', 'vase', 'pot', 'flowerpot', 'sink', 'column', 'dog', 'food', 'armchair', 'faucet', 'wall socket', 'body', 'knob', 'sconce', 'pillow', 'base', 'headboard', 'stairs', 'cat', 'license plate', 'plate', 'top', 'bowl', 'screen', 'clock', 'bag', 'pillar', 'seat cushion', 'bicycle', 'stove', 'wing', 'coffee table', 'ashcan', 'roof', 'bench', 'spotlight', 'boat', 'basket', 'work surface', 'living_room-s', 'desk', 'bird', 'leather', 'bathroom-s', 'house', 'plaything', 'pane', 'kitchen-s', 'sea', 'double door', 'rim', 'television', 'taillight', 'back pillow', 'chandelier', 'balcony', 'windshield', 'switch', 'pottedplant', 'path', 'stairway', 'cup', 'van', 'cap', 'door frame', 'chest of drawers', 'truck', 'airplane', 'awning', 'traffic light', 'bannister', 'beak', 'seat base', 'poster', 'flag', 'inside arm', 'drinking glass', 'telephone', 'towel', 'frame', 'rope', 'tvmonitor', 'bush', 'bucket', 'stern', 'field', 'stool', 'tray', 'pedestal', 'fireplace', 'outside arm', 'trade name', 'oven', 'keyboard', 'footboard', 'fan', 'horse', 'motorbike', 'train', 'dining_room-s', 'plastic-clear', 'shelves', 'bathtub', 'toilet', 'refrigerator', 'saddle', 'laminate', 'apron', 'counter', 'handle bar', 'wardrobe', 'candlestick', 'computer', 'palm', 'shop window', 'brick', 'bus', 'board', 'blind', 'chimney', 'microwave', 'sand', 'track', 'fluorescent', 'step', 'sculpture', 'engine', 'countertop', 'wallpaper', 'swivel chair', 'lid', 'loudspeaker', 'side', 'skirt', 'pipe', 'chain wheel', 'skyscraper-s', 'snow', 'river', 'air conditioner', 'bumper', 'ottoman', 'jar', 'skin', 'coach', 'pack', 'highway-s', 'canopy', 'stile', 'bridge', 'blotchy', 'cardboard', 'minibike', 'figurine', 'skyscraper', 'can', 'sheep', 'concrete', 'wicker', 'mouse', 'bookcase', 'bedclothes', 'exhaust hood', 'hill', 'cow', 'napkin', 'button panel', 'doorframe', 'manhole', 'crosswalk', 'umbrella', 'case', 'autobus', 'dishwasher', 'monitor', 'container', 'shutter', 'hoof', 'front', 'water tank', 'text', 'knife', 'building_facade-s', 'crt screen', 'curb', 'magazine', 'monitoring device', 'beam', 'gate', 'dotted', 'radiator', 'platform', 'blanket', 'central reservation', 'grill', 'bulletin board', 'laptop', 'shoe', 'pool table', 'fruit', 'coffee maker', 'candle', 'backplate', 'banded', 'handbag', 'wineglass', 'mug', 'apparel', 'striped', 'land', 'pitcher', 'remote control', 'bar', 'ball', 'conference_room-s', 'hotel_room-s', 'grandstand', 'backpack', 'pane of glass', 'face', 'ladder', 'bumpy', 'hedge', 'arm panel', 'fork', 'tower', 'notebook', 'toilet tissue', 'vent', 'muntin', 'screen door', 'brush', 'heater', 'booklet', 'kitchen island', 'post', 'stretcher', 'smeared', 'knitted', 'porous', 'plane', 'fibrous', 'pitted', 'sash', 'veined', 'shower', 'mountain_snowy-s', 'perforated', 'woven', 'soap dispenser', 'meshed', 'crosshatched', 'computer case', 'spoon', 'sprinkled', 'polka-dotted', 'grid', 'buffet', 'kettle', 'marbled', 'stained', 'metal shutter', 'traveling bag', 'stage', 'hat', 'printer', 'gauzy', 'interlaced', 'blade', 'zigzagged', 'frilly', 'teapot', 'spiralled', 'swirly', 'chest', 'matted', 'cracked', 'studded', 'embankment', 'cloud', 'horn', 'flecked', 'potholed', 'stratified', 'braided', 'lined', 'scaly', 'paisley', 'wrinkled', 'waffled', 'freckled', 'honeycombed', 'document', 'office-s', 'rack', 'chequered', 'corridor-s', 'lacelike', 'crystalline', 'windows', 'bubbly', 'silver screen', 'pleated', 'cobwebbed', 'grooved', 'animal', 'pier', 'crane', 'fur', 'airport_terminal-s', 'tap', 'lower sash', 'statue', 'postbox', 'dome', 'dormer', 'wire', 'console table', 'rubber', 'trunk', 'game_room-s', 'camera', 'microphone', 'waiting_room-s', 'jacket', 'dishrag', 'poolroom-home-s', 'home_office-s', 'fountain', 'upper sash', 'paper towel', 'washer', 'partition', 'entrance', 'banner', 'runway', 'corner pocket', 'art_studio-s', 'tent', 'spindle', 'towel rack', 'attic-s', 'forest-broadleaf-s', 'park-s', 'mountain-s', 'waterfall', 'guitar', 'system', 'place mat', 'diffusor', 'foliage', 'bouquet', 'side rail', 'coast-s', 'booth', 'dirt track', 'vending machine', 'alley-s', 'deck chair', 'canister', 'hovel', 'skylight', 'helmet', 'telephone booth', 'net', 'shirt', 'parlor-s', 'cradle', 'candelabrum', 'closet-s', 'beach-s', 'easel', 'childs_room-s', 'art_gallery-s', 'cart', 'newspaper', 'cross', 'smoke', 'footbridge', 'casing', 'apartment_building-outdoor-s', 'arcade machine', 'machine', 'baby buggy', 'tank', 'shower stall', 'swimming pool', 'sales booth', 'scaffolding', 'sill', 'staircase-s', 'castle-s', 'fridge', 'patty', 'altar', 'pasture-s', 'streetcar', 'dorm_room-s', 'blackboard', 'tapestry', 'trouser', 'billboard', 'nursery-s', 'decoration', 'lobby-s', 'garage-indoor-s', 'reception-s', 'hot tub', 'garage door', 'file cabinet', 'drawing', 'piano', 'bar-s', 'conveyer belt', 'arcade', 'equipment', 'saucepan', 'forest-needleleaf-s', 'shaft', 'court', 'head roof', 'capital', 'bakery-shop-s', 'roundabout-s', 'warehouse-indoor-s', 'lake', 'barrel', 'ship', 'house-s', 'cage', 'railroad train', 'arch', 'lighthouse', 'bell', 'bus stop', 'exhibitor', 'jersey', 'plinth', 'forecourt', 'eiderdown', 'mat', 'cash register', 'casino-indoor-s', 'calendar', 'briefcase', 'field-cultivated-s', 'bridge-s', 'classroom-s', 'river-s', 'fire escape', 'mouse pad', 'cd', 'rocking chair', 'bread', 'youth_hostel-s', 'cliff', 'field-wild-s', 'escalator', 'fuselage', 'baseboard', 'lighthouse-s', 'clouds', 'elevator', 'table football', 'grand piano', 'earmuffs', 'creek-s', 'museum-indoor-s', 'shoe_shop-s', 'window_seat-s', 'scale', 'amusement_park-s', 'dinette-vehicle-s', 'vault', 'radio', 'lake-natural-s', 'dinette-home-s', 'riser', 'cockpit-s', 'fish', 'panel', 'tread', 'boot', 'stabilizer', 'jacuzzi-indoor-s', 'linoleum', 'dummy', 'playroom-s', 'mezzanine', 'fire place', 'map', 'menu', 'parking_lot-s', 'valley-s', 'rubbish', 'gym shoe', 'auditorium-s', 'beauty_salon-s', 'tower-s', 'slot machine', 'arcades', 'basketball hoop', 'wet_bar-s', 'artists_loft-s', 'tire', 'balcony-interior-s', 'video player', 'arrival_gate-outdoor-s', 'merchandise', 'television stand', 'playground-s', 'plaza-s', 'ice', 'playground', 'guardrail', 'hill-s', 'deck', 'table tennis', 'mattress', 'bidet', 'sweater', 'clothing_store-s', 'utility_room-s', 'bow_window-indoor-s', 'pantry-s', 'aircraft carrier', 'valley', 'railway', 'balloon', 'galley-s', 'bookstore-s', 'abbey-s', 'basement-s', 'pitch', 'display board', 'cockpit', 'pallet', 'supermarket-s', 'golf_course-s', 'patio', 'ad', 'price tag', 'coach roof', 'hallway-s', 'controls', 'island', 'metal shutters', 'laundromat-s', 'ballroom-s', 'greenhouse-indoor-s', 'gazebo-exterior-s', 'market-outdoor-s', 'subway_interior-s', 'curtains', 'porch', 'bottle rack', 'duck', 'gas pump', 'bus_interior-s', 'doorway-indoor-s', 'alcove-s', 'pulpit', 'ramp', 'access_road-s', 'landing_deck-s', 'archive-s', 'leaves', 'slope', 'helicopter', 'podium', 'steering wheel', 'finger', 'monument', 'trailer', 'gymnasium-indoor-s', 'waterfall-block-s', 'windmill', 'pool', 'water tower', 'folding screen', 'workbench', 'brushes', 'leaf', 'scoreboard', 'cathedral-indoor-s', 'office_building-s', 'baggage_claim-s', 'badlands-s', 'forest_path-s', 'home_theater-s', 'ocean-s', 'ice rink', 'carport', 'gravestone', 'straw', 'horse-drawn carriage', 'tunnel', 'cannon', 'tumble dryer', 'fastfood_restaurant-s', 'gas_station-s', 'church-indoor-s', 'harbor-s', 'amusement_arcade-s', 'poolroom-establishment-s', 'bowling_alley-s', 'auto_showroom-s', 'library-indoor-s', 'restaurant-s', 'toyshop-s', 'dentists_office-s', 'altarpiece', 'shelter', 'pond', 'windscreen', 'wheelchair', 'coat', 'planter', 'player', 'bow_window-outdoor-s', 'driveway-s', 'fairway-s', 'courthouse-s', 'yard-s', 'theater-indoor_procenium-s', 'parking_garage-indoor-s', 'construction_site-s', 'carousel', 'display window', 'elevator door', 'shop', 'roundabout', 'blinds', 'slide', 'amphitheater-s', 'ball_pit-s', 'desert-sand-s', 'control_tower-outdoor-s', 'cubicle-office-s', 'computer_room-s', 'kindergarden_classroom-s', 'water_tower-s', 'campus-s', 'airplane_cabin-s', 'music_studio-s', 'aquarium', 'ruins', 'instrument panel', 'ring', 'table game', 'television camera', 'control tower', 'goal', 'delicatessen-s', 'swimming_pool-outdoor-s', 'cloister-indoor-s', 'wine_cellar-barrel_storage-s', 'restaurant_patio-s', 'weighbridge-s', 'shopping_mall-indoor-s', 'berth-s', 'bird cage', 'aqueduct', 'weighbridge', 'bedpost', 'terrace', 'geodesic_dome-outdoor-s', 'swimming_pool-indoor-s', 'waterfall-fan-s', 'ice_skating_rink-indoor-s', 'cemetery-s', 'windmill-s', 'videostore-s', 'reading_room-s', 'folding door', 'stands', 'revolving door', 'mill', 'movie_theater-indoor-s', 'sauna-s', 'day_care_center-s', 'dining_car-s', 'jail_cell-s', 'mansion-s', 'courtroom-s', 'atrium-public-s', 'pantry', 'bandstand', 'videos', 'sand trap', 'organ', 'synthesizer', 'planks', 'pictures', 'parterre', 'doorway-outdoor-s', 'campsite-s', 'shower-s', 'florist_shop-indoor-s', 'hospital_room-s', 'inn-indoor-s', 'church-outdoor-s', 'lecture_room-s', 'mosque-outdoor-s', 'aqueduct-s', 'lockers', 'service station', 'trench', 'barrels', 'box office', 'binder', 'cabin', 'forklift', 'doors', 'pavilion', 'forest_road-s', 'cabin-outdoor-s', 'operating_room-s', 'inn-outdoor-s', 'greenhouse', 'caravan', 'berth', 'trellis', 'tomb', 'structure', 'plastic', 'parasol', 'sandbox-s', 'shopfront-s', 'planetarium-outdoor-s', 'snowfield-s', 'hayfield-s', 'carrousel-s', 'botanical_garden-s', 'barn-s', 'locker_room-s', 'crosswalk-s', 'television_studio-s', 'islet-s', 'slum-s', 'dam', 'tracks', 'hay', 'hen', 'recycling bin', 'disc case', 'diner-outdoor-s', 'ski_resort-s', 'monastery-outdoor-s', 'village-s', 'hunting_lodge-outdoor-s', 'marsh-s', 'fountain-s', 'subway_station-corridor-s', 'kitchenette-s', 'corn_field-s', 'kasbah-s', 'auto_factory-s', 'martial_arts_gym-s', 'balcony-exterior-s', 'courtyard-s', 'chicken_coop-outdoor-s', 'rope_bridge-s', 'shanties', 'wave', 'machinery', 'dashboard', 'dental chair', 'parking', 'sewing machine', 'rifle', 'kiosk-indoor-s', 'outhouse-outdoor-s', 'stage-indoor-s', 'art_school-s', 'viaduct-s', 'bleachers-outdoor-s', 'pulpit-s', 'garage-outdoor-s', 'corral-s', 'farm-s', 'baptistry-outdoor-s', 'wheat_field-s', 'arch-s', 'moor-s', 'hospital-s', 'runway-s', 'donjon-s', 'ruin-s', 'canyon-s', 'escalator-indoor-s', 'airport-s', 'desert', 'henhouse', 'tennis court', 'shed', 'bird feeder', 'washing machines', 'watchtower', 'shops', 'ride', 'telescope', 'slats', 'drum', 'fire', 'oar', 'breads', 'town_house-s', 'bank-outdoor-s', 'medina-s', 'candy_store-s', 'palace-s', 'mountain_path-s', 'fire_escape-s', 'dolmen-s', 'dacha-s', 'jail-indoor-s', 'car_interior-backseat-s', 'jewelry_shop-s', 'bus_depot-outdoor-s', 'embassy-s', 'elevator-interior-s', 'cavern-indoor-s', 'casino-outdoor-s', 'kennel-indoor-s', 'cathedral-outdoor-s', 'vegetable_garden-s', 'hot_spring-s', 'sandbar-s', 'observatory-outdoor-s', 'desert-vegetation-s', 'conference_center-s', 'covered_bridge-exterior-s', 'semidesert ground', 'grille door', 'roller coaster', 'water wheel', 'barbecue', 'bulldozer', 'steam shovel', 'gravel', 'meter', 'excavator', 'irrigation_ditch-s', 'dam-s', 'ranch_house-s', 'ranch-s', 'carport-outdoor-s', 'ghost_town-s', 'canal-urban-s', 'booth-indoor-s', 'hotel-outdoor-s', 'boxing_ring-s', 'stadium-baseball-s', 'fence-s', 'airport-entrance-s', 'excavation-s', 'ice_cream_parlor-s', 'student_residence-s', 'motel-s', 'sacristy-s', 'lift_bridge-s', 'junk_pile-s', 'hangar-indoor-s', 'flood-s', 'wrestling_ring-indoor-s', 'ski_slope-s', 'fitting_room-exterior-s', 'crevasse-s', 'elevator_lobby-s', 'estuary-s', 'bazaar-indoor-s', 'subway_station-platform-s', 'wine_cellar-bottle_storage-s', 'watchtower-s', 'kennel-outdoor-s', 'boathouse-s', 'greenhouse-outdoor-s', 'fitting_room-interior-s', 'vineyard-s', 'oast_house-s', 'moat-water-s', 'kiosk-outdoor-s', 'convenience_store-outdoor-s', 'nuclear_power_plant-outdoor-s', 'podium-indoor-s', 'orchard-s', 'movie_theater-outdoor-s', 'mountain_road-s', 'temple-east_asia-s', 'badminton_court-outdoor-s', 'vineyard', 'rubble', 'badlands', 'forest', 'ticket counter', 'stalls', 'shower curtain', 'village', 'safety side', 'gas station', 'niche', 'check-in-desk', 'set of instruments', 'bread rolls', 'coffee_shop-s', 'labyrinth-indoor-s', 'lawn-s', 'beach_house-s', 'escalator-outdoor-s', 'chalet-s', 'baseball_field-s', 'sun_deck-s', 'guardhouse-s', 'hut-s', 'flight_of_stairs-urban-s', 'waterfall-cascade-s', 'general_store-outdoor-s', 'mine-s', 'herb_garden-s', 'mosque-indoor-s', 'lagoon-s', 'topiary_garden-s', 'industrial_area-s', 'shed-s', 'pagoda-s', 'water_mill-s', 'elevator-door-s', 'cloister-outdoor-s', 'butchers_shop-s', 'apse-indoor-s', 'ice_skating_rink-outdoor-s', 'synagogue-outdoor-s', 'assembly_line-s', 'manufactured_home-s', 'firing_range-outdoor-s', 'barbershop-s', 'cottage_garden-s', 'hacienda-s', 'industrial_park-s', 'workshop-s', 'dugout-s', 'hat_shop-s', 'elevator-freight_elevator-s', 'spa-massage_room-s', 'savanna-s', 'bank-indoor-s', 'oasis-s', 'witness_stand-s', 'road_cut-s', 'volleyball_court-outdoor-s', 'anechoic_chamber-s', 'train_station-outdoor-s', 'canal-natural-s', 'parking_garage-outdoor-s', 'food_court-s', 'downtown-s', 'driving_range-outdoor-s', 'catwalk-s', 'market-indoor-s', 'carport-freestanding-s', 'elevator_shaft-s', 'moon_bounce-s', 'formal_garden-s', 'cargo_container_interior-s', 'bog-s', 'airport_ticket_counter-s', 'lido_deck-outdoor-s', 'military_hut-s', 'baptistry-indoor-s', 'bullring-s', 'library-outdoor-s', 'inflatable bounce game', 'temple', 'bowling alley', 'mosque', 'skittle alley', 'sandbox', 'catwalk', 'big top', 'iceberg', 'viaduct', 'fog bank', 'parking lot', 'trestle', 'table cloth', 'tables', 'pigeonhole', 'cactus', 'bathrobe', 'rudder', 'crate', 'quay', 'hand cart', 'candies', 'control_tower-indoor-s', 'mausoleum-s', 'liquor_store-indoor-s', 'choir_loft-exterior-s', 'chapel-s', 'jacuzzi-outdoor-s', 'hot_tub-outdoor-s', 'imaret-s', 'heliport-s', 'dirt_track-s', 'batters_box-s', 'quadrangle-s', 'liquor_store-outdoor-s', 'bazaar-outdoor-s', 'hoodoo-s', 'dining_hall-s', 'banquet_hall-s', 'basketball_court-outdoor-s', 'gulch-s', 'granary-s', 'pilothouse-indoor-s', 'natural_history_museum-s', 'bakery-kitchen-s', 'cottage-s', 'cabana-s', 'landing-s', 'signal_box-s', 'checkout_counter-s', 'labyrinth-outdoor-s', 'bus_shelter-s', 'zen_garden-s', 'fishpond-s', 'gift_shop-s', 'watering_hole-s', 'hot_tub-indoor-s', 'call_center-s', 'air_base-s', 'manhole-s', 'joss_house-s', 'badminton_court-indoor-s', 'fjord-s', 'limousine_interior-s', 'backstairs-s', 'moat-dry-s', 'cardroom-s', 'brewery-outdoor-s', 'loading_dock-s', 'clean_room-s', 'convenience_store-indoor-s', 'barnyard-s', 'car_dealership-s', 'tearoom-s', 'museum-outdoor-s', 'fire_station-s', 'bedchamber-s', 'bistro-indoor-s', 'butte-s', 'field_road-s', 'rubble-s', 'hedge_maze-s', 'flight_of_stairs-natural-s', 'aquatic_theater-s', 'mission-s', 'lean-to-s', 'basketball_court-indoor-s', 'newsstand-outdoor-s', 'football_field-s', 'freeway-s', 'hangar-outdoor-s', 'cafeteria-s', 'building_complex-s', 'covered_bridge-interior-s', 'bayou-s', 'throne_room-s', 'hunting_lodge-indoor-s', 'funeral_chapel-s', 'beer_garden-s', 'bullpen-s', 'archaelogical_excavation-s', 'junkyard-s', 'bank_vault-s', 'cheese_factory-s', 'lake-artificial-s', 'florist_shop-outdoor-s', 'hotel_breakfast_area-s', 'canteen-s', 'catacomb-s', 'drainage_ditch-s', 'auto_mechanics-indoor-s', 'bleachers-indoor-s', 'nunnery-s', 'earth_fissure-s', 'japanese_garden-s', 'fort-s', 'circus_tent-outdoor-s', 'jail-outdoor-s', 'pub-outdoor-s', 'cubicle-library-s', 'labyrinth', 'bullring', 'terraces', 'acropolis', 'covered bridge', 'shipyard', 'ticket window', 'elephant', 'toll booth', 'book stand', 'skeleton', 'baptismal font', 'witness stand', 'vegetables', 'mountain pass', 'meat', 'canvas', 'shore']\n",
      "['color', 'object', 'part', 'material', 'scene', 'texture']\n",
      "[5 0 0 ..., 1 1 1]\n"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "\n",
    "generator = torch.load(\"gen_mnist_model_epoch_200.pt\", map_location='cpu')\n",
    "print(generator)\n",
    "# generater.load_state_dict(torch.load(\".sample_data/gen_mnist_model_epoch_200.pt\", map_location='cpu'))\n",
    "# generater.eval()\n"
=======
    "segments = 'quick-netdissect/dataset/broden'\n",
    "imgsize = (227, 227)\n",
    "broden_version = 1\n",
    "perturbation = None\n",
    "download = False\n",
    "size = 10000\n",
    "\n",
    "# Load broden dataset\n",
    "ds = try_to_load_broden(segments, imgsize, broden_version, perturbation, download, size)\n",
    "\n",
    "if ds is None:\n",
    "    ds = try_to_load_multiseg(segments, imgsize,perturbation, size)\n",
    "\n",
    "print(ds.labels)\n",
    "print(ds.categories)\n",
    "print(ds.label_category)"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "PTWwHQA2tnxM"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "\n",
    "def get_multi_mnist_dataloaders(batch_size=128):\n",
    "    # Resize images so they are a power of 2\n",
    "    all_transforms = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "#         transforms.Resize(32),\n",
    "        transforms.Resize(100),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_data = MultiMNIST('MNIST_synthetic.h5',  train = True, transform = all_transforms)\n",
    "    test_data = MultiMNIST('MNIST_synthetic.h5', train = False, transform = all_transforms)\n",
    "\n",
    "    # Create dataloaders\n",
    "#     train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "#     test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=16)\n",
    "#     return train_loader, test_loader\n",
    "    return train_data, test_data\n",
    "\n",
    "class MultiMNIST(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, path = 'MNIST_synthetic.h5', train = True, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        super(MultiMNIST, self).__init__()\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "        f = h5py.File(self.path, 'r')\n",
    "\n",
    "        if train:\n",
    "            self.X = list(f['train_dataset'])\n",
    "            self.y = list(f['train_labels'])\n",
    "            self.seg = list(f['train_segmentations'])\n",
    "\n",
    "        else:\n",
    "            self.X = list(f['test_dataset'])\n",
    "            self.y = list(f['test_labels'])\n",
    "            self.seg = list(f['test_segmentations'])\n",
    "\n",
    "        if False:\n",
    "            self.X = list(f['val_dataset'])\n",
    "            self.y = list(f['val_labels'])\n",
    "            self.seg = list(f['val_segmentations'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "#     def __iter__(self):\n",
    "#         return DataLoaderIter(self)\n",
    "\n",
    "    def __getitem__(self, index):#, seg=False):\n",
    "\n",
    "        img = self.X[index]\n",
    "        target = self.y[index]\n",
    "        seg = self.seg[index]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target, seg"
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGE_STDEV = [0.229, 0.224, 0.225]\n",
    "\n",
    "bds = BrodenDataset(directory='quick-netdissect/dataset/broden',broden_version=1,download=False,resolution=227,\n",
    "                   transform_image=transforms.Compose([\n",
    "                        transforms.Resize(224),\n",
    "                        transforms.ToTensor()]))"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sxcFUhfCg3pG"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'netdissect'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f53c5317ad50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnetdissect\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mretain_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdissect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnetdissect\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mReverseNormalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'netdissect'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from netdissect import retain_layers, dissect\n",
    "from netdissect import ReverseNormalize\n",
    "\n",
    "generator.eval()\n",
    "generator.cuda()\n",
    "  \n",
    "#   for name, layer in generator.named_modules():\n",
    "#     print(name)\n",
    "#============ result: \n",
    "# latent_to_features\n",
    "# latent_to_features.0\n",
    "# latent_to_features.1\n",
    "# features_to_image\n",
    "# features_to_image.0\n",
    "# features_to_image.1\n",
    "# features_to_image.2\n",
    "# features_to_image.3\n",
    "# features_to_image.4\n",
    "# features_to_image.5\n",
    "# features_to_image.6\n",
    "# features_to_image.7\n",
    "# features_to_image.8\n",
    "# features_to_image.9\n",
    "# features_to_image.10\n",
    "\n",
    "retain_layers(generator, ['features_to_image.0',\n",
    "                          'features_to_image.1', \n",
    "                          'features_to_image.2', \n",
    "                          'features_to_image.3', \n",
    "                          'features_to_image.4',\n",
    "                          'features_to_image.5',\n",
    "                          'features_to_image.6',\n",
    "                          'features_to_image.7',\n",
    "                          'features_to_image.8',\n",
    "                          'features_to_image.9',\n",
    "                          'features_to_image.10'])\n",
    "bds, _ = get_multi_mnist_dataloaders()\n",
    "dissect('sample_data/', generator, bds,\n",
    "        recover_image=ReverseNormalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        batch_size=100,\n",
    "        examples_per_unit=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'netdissect'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f15feeea1511>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnetdissect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'netdissect'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    " import netdissect"
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are startingg!\n",
      " segloader!!!\n",
      "collect stuff\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961f248073d24d1e8d91881f5c7b6cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Quantiles', max=44404), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dissect('result/dissect', model, bds,\n",
    "        recover_image=ReverseNormalize(IMAGE_MEAN, IMAGE_STDEV),\n",
    "        batch_size=1,\n",
    "        examples_per_unit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'quick-netdissect/dataset/broden1_384/category.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-eeeb54ab83a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             transforms.Normalize(IMAGE_MEAN, IMAGE_STDEV)]),\n\u001b[0;32m---> 19\u001b[0;31m         size=100)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m# run dissect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m dissect('dissect/test', model, bds,\n",
      "\u001b[0;32m~/Desktop/Berkeley/courses/deeplearning/project/CS-294-131-Trustworthy-Deep-Learning/quick-netdissect/netdissect/broden.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, resolution, split, categories, transform_image, transform_segment, download, size, include_bincount, broden_version, max_segment_depth)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_segment_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_segment_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         with open(os.path.join(self.resdir, 'category.csv'),\n\u001b[0;32m---> 43\u001b[0;31m                 encoding='utf-8') as f:\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'quick-netdissect/dataset/broden1_384/category.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "model = alexnet(pretrained=True)\n",
    "model.eval()\n",
    "# Load an alexnet\n",
    "retain_layers(model, [\n",
    "    ('features.0', 'conv1'),\n",
    "    ('features.3', 'conv2'),\n",
    "    ('features.6', 'conv3'),\n",
    "    ('features.8', 'conv4'),\n",
    "    ('features.10', 'conv5') ])\n",
    "# load broden dataset\n",
    "bds = BrodenDataset('quick-netdissect/dataset/',\n",
    "        transform_image=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(IMAGE_MEAN, IMAGE_STDEV)]),\n",
    "        size=100)\n",
    "# run dissect\n",
    "dissect('dissect/test', model, bds,\n",
    "        recover_image=ReverseNormalize(IMAGE_MEAN, IMAGE_STDEV),\n",
    "        examples_per_unit=10)"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3rpC_C88qsv7"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WVqROMVQqiHc"
   },
=======
   "metadata": {},
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "dissect_MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
=======
   "display_name": "Python (pyspark)",
   "language": "python",
   "name": "pyspark"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.6.8"
=======
   "version": "3.5.6"
>>>>>>> 4aac6e072d8c979ac616b49204cff87319466336
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
